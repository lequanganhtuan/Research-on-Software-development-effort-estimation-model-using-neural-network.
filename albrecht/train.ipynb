{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22011d63",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ede778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Kiểm tra dữ liệu ===\n",
      "Kích thước: (24, 7)\n",
      "Các cột: ['Input', 'Output', 'Inquiry', 'File', 'FPAdj', 'RawFPcounts', 'Effort']\n",
      "Mẫu 5 hàng đầu tiên:\n",
      "      Input    Output   Inquiry      File     FPAdj  RawFPcounts    Effort\n",
      "0 -0.544978  2.676655  2.425098  2.235928  0.078752     2.030029  1.905014\n",
      "1  2.060336  1.583672  2.425098  1.423982  0.078752     2.030029  1.905014\n",
      "2  1.835512 -0.602296 -1.141891 -0.347538 -1.433293    -0.158757 -0.364603\n",
      "3  0.248519  0.413717  0.417448 -0.347538  1.212786     0.236318  0.476385\n",
      "4 -1.338474  0.690812 -1.063924 -0.568978 -0.677270    -0.336098  1.123946\n",
      "\n",
      "Thông tin dữ liệu:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24 entries, 0 to 23\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Input        24 non-null     float64\n",
      " 1   Output       24 non-null     float64\n",
      " 2   Inquiry      24 non-null     float64\n",
      " 3   File         24 non-null     float64\n",
      " 4   FPAdj        24 non-null     float64\n",
      " 5   RawFPcounts  24 non-null     float64\n",
      " 6   Effort       24 non-null     float64\n",
      "dtypes: float64(7)\n",
      "memory usage: 1.4 KB\n",
      "None\n",
      "\n",
      "=== Sau khi tăng cường dữ liệu bằng nhiễu Gaussian ===\n",
      "X_augmented shape: (72, 6)\n",
      "y_augmented shape: (72,)\n",
      "\n",
      "=== Kích thước dữ liệu sau reshape ===\n",
      "X_augmented shape: (72, 6, 1)\n",
      "y_augmented shape: (72,)\n",
      "\n",
      "✅ Kích thước dữ liệu CNN:\n",
      " - X_train: (61, 6, 1)\n",
      " - X_test : (11, 6, 1)\n",
      "🚀 Chạy PSO để tìm siêu tham số tối ưu...\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000002BD480A5C60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000002BD480A5C60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "🔁 Iteration 1/15\n",
      "\n",
      "🔁 Iteration 2/15\n",
      "\n",
      "🔁 Iteration 3/15\n",
      "\n",
      "🔁 Iteration 4/15\n",
      "\n",
      "🔁 Iteration 5/15\n",
      "✅ Cập nhật g_best: Score = 0.3496\n",
      "✅ Cập nhật g_best: Score = 0.3274\n",
      "\n",
      "🔁 Iteration 6/15\n",
      "\n",
      "🔁 Iteration 7/15\n",
      "\n",
      "🔁 Iteration 8/15\n",
      "\n",
      "🔁 Iteration 9/15\n",
      "\n",
      "🔁 Iteration 10/15\n",
      "✅ Cập nhật g_best: Score = 0.3122\n",
      "\n",
      "🔁 Iteration 11/15\n",
      "\n",
      "🔁 Iteration 12/15\n",
      "\n",
      "🔁 Iteration 13/15\n",
      "✅ Cập nhật g_best: Score = 0.3029\n",
      "\n",
      "🔁 Iteration 14/15\n",
      "\n",
      "🔁 Iteration 15/15\n",
      "🏆 Siêu tham số tốt nhất: {'filters': 2, 'kernel_size': 2, 'l2_reg': 0.001, 'dense_units': 35, 'dropout_rate': np.float64(0.2072292288550723), 'learning_rate': np.float64(0.0009095629001577539), 'batch_size': 7, 'epochs': 107}\n",
      "📉 Score tốt nhất: 0.3029\n",
      "\n",
      "📂 Fold 1/5\n",
      "✅ Fold 1 RMSE: 0.6887\n",
      "\n",
      "📂 Fold 2/5\n",
      "✅ Fold 2 RMSE: 0.5578\n",
      "\n",
      "📂 Fold 3/5\n",
      "✅ Fold 3 RMSE: 0.2759\n",
      "\n",
      "📂 Fold 4/5\n",
      "✅ Fold 4 RMSE: 0.2812\n",
      "\n",
      "📂 Fold 5/5\n",
      "✅ Fold 5 RMSE: 0.2496\n",
      "\n",
      "📊 RMSE trung bình qua 5 folds: 0.4106\n",
      "\n",
      "📈 Kết quả đánh giá bootstrap (trên giá trị đã scale):\n",
      "📌 MSE     : 0.2511 ± 0.1338\n",
      "📌 RMSE    : 0.4805 ± 0.1422\n",
      "📌 MAE     : 0.3276 ± 0.1120\n",
      "📌 R²      : 0.7246 ± 0.1731\n",
      "📌 MAPE    : 37.11% ± 11.45%\n",
      "📌 MMRE    : 0.3711 ± 0.1145\n",
      "📌 MdMRE   : 0.2315 ± 0.1709\n",
      "📌 PRED(25): 62.98% ± 14.22%\n",
      "\n",
      "Đã lưu kết quả đánh giá vào 'cnn_evaluation_results_scaled.csv'\n",
      "\n",
      "Đã lưu hình ảnh trực quan hóa vào 'cnn_visualization_results_scaled.png'\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Dense, Dropout, Input, BatchNormalization, GlobalAveragePooling1D\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from uuid import uuid4\n",
    "\n",
    "# Thiết lập seed để tái lập\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Hàm tính các chỉ số đánh giá\n",
    "def calculate_mape(y_true, y_pred):\n",
    "    mask = y_true != 0\n",
    "    if np.sum(mask) == 0:\n",
    "        return np.nan\n",
    "    return np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100\n",
    "\n",
    "def calculate_mmre(y_true, y_pred):\n",
    "    mask = y_true != 0\n",
    "    if np.sum(mask) == 0:\n",
    "        return np.nan\n",
    "    return np.mean(np.abs(((y_true[mask] - y_pred[mask]) / y_true[mask])))\n",
    "\n",
    "def calculate_mdmre(y_true, y_pred):\n",
    "    mask = y_true != 0\n",
    "    if np.sum(mask) == 0:\n",
    "        return np.nan\n",
    "    return np.median(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask]))\n",
    "\n",
    "def calculate_pred25(y_true, y_pred):\n",
    "    mask = y_true != 0\n",
    "    if np.sum(mask) == 0:\n",
    "        return np.nan\n",
    "    mre = np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])\n",
    "    return np.mean(mre <= 0.25) * 100\n",
    "\n",
    "# Đọc dữ liệu đã tiền xử lý\n",
    "df = pd.read_csv('albrecht_cleaned.csv')\n",
    "\n",
    "# Kiểm tra dữ liệu\n",
    "print(\"=== Kiểm tra dữ liệu ===\")\n",
    "print(\"Kích thước:\", df.shape)\n",
    "print(\"Các cột:\", df.columns.tolist())\n",
    "print(\"Mẫu 5 hàng đầu tiên:\")\n",
    "print(df.head())\n",
    "print(\"\\nThông tin dữ liệu:\")\n",
    "print(df.info())\n",
    "\n",
    "# Chọn đặc trưng và biến mục tiêu\n",
    "features = [col for col in df.columns if col not in ['Effort']]\n",
    "X = df[features].values\n",
    "y = df['Effort'].values  # Sử dụng Effort đã được scale từ file test.csv\n",
    "\n",
    "# Tăng cường dữ liệu bằng nhiễu Gaussian\n",
    "def add_gaussian_noise(X, noise_factor=0.05):\n",
    "    noise = np.random.normal(loc=0, scale=noise_factor, size=X.shape)\n",
    "    return X + noise\n",
    "\n",
    "X_augmented = X.copy()\n",
    "y_augmented = y.copy()\n",
    "for _ in range(2):  # Tạo thêm 2 bản sao với nhiễu\n",
    "    X_noisy = add_gaussian_noise(X, noise_factor=0.05)\n",
    "    X_augmented = np.vstack((X_augmented, X_noisy))\n",
    "    y_augmented = np.hstack((y_augmented, y))\n",
    "\n",
    "print(\"\\n=== Sau khi tăng cường dữ liệu bằng nhiễu Gaussian ===\")\n",
    "print(\"X_augmented shape:\", X_augmented.shape)\n",
    "print(\"y_augmented shape:\", y_augmented.shape)\n",
    "\n",
    "# Reshape dữ liệu thành dạng (samples, features, 1) cho Conv1D\n",
    "X_augmented = X_augmented.reshape(X_augmented.shape[0], X_augmented.shape[1], 1)\n",
    "\n",
    "print(\"\\n=== Kích thước dữ liệu sau reshape ===\")\n",
    "print(\"X_augmented shape:\", X_augmented.shape)\n",
    "print(\"y_augmented shape:\", y_augmented.shape)\n",
    "\n",
    "# Chia tập train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_augmented, y_augmented, test_size=0.15, random_state=42)\n",
    "\n",
    "print(f\"\\n✅ Kích thước dữ liệu CNN:\")\n",
    "print(f\" - X_train: {X_train.shape}\")\n",
    "print(f\" - X_test : {X_test.shape}\")\n",
    "\n",
    "# Xây dựng mô hình CNN với Conv1D, BatchNormalization, GlobalAveragePooling1D\n",
    "def build_cnn_model(filters=8, kernel_size=2, l2_reg=0.01, dense_units=16, dropout_rate=0.3, learning_rate=0.001):\n",
    "    l2_reg = max(l2_reg, 0.001)\n",
    "    model = Sequential([\n",
    "        Input(shape=(X_train.shape[1], X_train.shape[2])),\n",
    "        Conv1D(filters, kernel_size, activation='relu', padding='same', kernel_regularizer=l2(l2_reg)),\n",
    "        BatchNormalization(),\n",
    "        Conv1D(filters, kernel_size, activation='relu', padding='same', kernel_regularizer=l2(l2_reg)),\n",
    "        BatchNormalization(),\n",
    "        GlobalAveragePooling1D(),\n",
    "        Dense(dense_units, activation='relu', kernel_regularizer=l2(l2_reg)),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(1, activation='linear')\n",
    "    ])\n",
    "    \n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss=tf.keras.losses.Huber(), metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# Không gian siêu tham số\n",
    "param_bounds = {\n",
    "    'filters': (4, 32),\n",
    "    'kernel_size': (1, 3),\n",
    "    'l2_reg': (0.001, 0.1),\n",
    "    'dense_units': (8, 64),\n",
    "    'dropout_rate': (0.2, 0.5),\n",
    "    'learning_rate': (1e-4, 1e-2),\n",
    "    'batch_size': (8, 32),\n",
    "    'epochs': (50, 150)\n",
    "}\n",
    "\n",
    "# Hàm mã hóa & giải mã particle\n",
    "def random_particle():\n",
    "    return np.array([\n",
    "        np.random.randint(param_bounds['filters'][0], param_bounds['filters'][1] + 1),\n",
    "        np.random.randint(param_bounds['kernel_size'][0], param_bounds['kernel_size'][1] + 1),\n",
    "        np.random.uniform(param_bounds['l2_reg'][0], param_bounds['l2_reg'][1]),\n",
    "        np.random.randint(param_bounds['dense_units'][0], param_bounds['dense_units'][1] + 1),\n",
    "        np.random.uniform(param_bounds['dropout_rate'][0], param_bounds['dropout_rate'][1]),\n",
    "        np.random.uniform(param_bounds['learning_rate'][0], param_bounds['learning_rate'][1]),\n",
    "        np.random.randint(param_bounds['batch_size'][0], param_bounds['batch_size'][1] + 1),\n",
    "        np.random.randint(param_bounds['epochs'][0], param_bounds['epochs'][1] + 1)\n",
    "    ])\n",
    "\n",
    "def decode_particle(particle):\n",
    "    params = {\n",
    "        'filters': int(particle[0]),\n",
    "        'kernel_size': int(particle[1]),\n",
    "        'l2_reg': particle[2],\n",
    "        'dense_units': int(particle[3]),\n",
    "        'dropout_rate': particle[4],\n",
    "        'learning_rate': particle[5],\n",
    "        'batch_size': int(particle[6]),\n",
    "        'epochs': int(particle[7])\n",
    "    }\n",
    "    # Đảm bảo l2_reg không âm\n",
    "    params['l2_reg'] = max(params['l2_reg'], 0.001)\n",
    "    params['l2_reg'] = min(params['l2_reg'], param_bounds['l2_reg'][1])  # Giới hạn trên\n",
    "    return params\n",
    "\n",
    "# Hàm fitness cho PSO\n",
    "def fitness_function(particle):\n",
    "    params = decode_particle(particle)\n",
    "    model = build_cnn_model(**{k: v for k, v in params.items() if k != 'batch_size' and k != 'epochs'})\n",
    "    \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    rmse_scores = []\n",
    "    \n",
    "    for train_idx, val_idx in kf.split(X_train):\n",
    "        X_tr, X_val = X_train[train_idx], X_train[val_idx]\n",
    "        y_tr, y_val = y_train[train_idx], y_train[val_idx]\n",
    "        \n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
    "        reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
    "        \n",
    "        model.fit(X_tr, y_tr, epochs=params['epochs'], batch_size=params['batch_size'], \n",
    "                validation_split=0.2, verbose=0, callbacks=[early_stopping, reduce_lr])\n",
    "        y_pred = model.predict(X_val, verbose=0)\n",
    "        rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "        rmse_scores.append(rmse)\n",
    "    \n",
    "    return np.mean(rmse_scores)\n",
    "\n",
    "# Triển khai PSO\n",
    "def run_pso_cnn(num_particles=10, max_iter=15):\n",
    "    dim = len(param_bounds)\n",
    "    bounds_array = np.array(list(param_bounds.values()))\n",
    "    \n",
    "    particles = [random_particle() for _ in range(num_particles)]\n",
    "    velocities = [np.zeros(dim) for _ in range(num_particles)]\n",
    "    \n",
    "    p_best_positions = particles.copy()\n",
    "    p_best_scores = [fitness_function(p) for p in particles]\n",
    "    \n",
    "    g_best_index = np.argmin(p_best_scores)\n",
    "    g_best_position = p_best_positions[g_best_index]\n",
    "    g_best_score = p_best_scores[g_best_index]\n",
    "    \n",
    "    w, c1, c2 = 0.5, 1.5, 1.5\n",
    "    \n",
    "    for iter in range(max_iter):\n",
    "        print(f\"\\n🔁 Iteration {iter + 1}/{max_iter}\")\n",
    "        for i in range(num_particles):\n",
    "            r1 = np.random.rand(dim)\n",
    "            r2 = np.random.rand(dim)\n",
    "            \n",
    "            velocities[i] = (\n",
    "                w * velocities[i]\n",
    "                + c1 * r1 * (p_best_positions[i] - particles[i])\n",
    "                + c2 * r2 * (g_best_position - particles[i])\n",
    "            )\n",
    "            \n",
    "            particles[i] += velocities[i]\n",
    "            particles[i] = np.clip(particles[i], bounds_array[:, 0], bounds_array[:, 1])\n",
    "            # Đảm bảo l2_reg không âm và trong giới hạn\n",
    "            particles[i][2] = max(particles[i][2], param_bounds['l2_reg'][0])\n",
    "            particles[i][2] = min(particles[i][2], param_bounds['l2_reg'][1])\n",
    "            particles[i][4] = np.clip(particles[i][4], param_bounds['dropout_rate'][0], param_bounds['dropout_rate'][1])\n",
    "            \n",
    "            score = fitness_function(particles[i])\n",
    "            \n",
    "            if score < p_best_scores[i]:\n",
    "                p_best_scores[i] = score\n",
    "                p_best_positions[i] = particles[i]\n",
    "                \n",
    "            if score < g_best_score:\n",
    "                g_best_score = score\n",
    "                g_best_position = particles[i]\n",
    "                print(f\"✅ Cập nhật g_best: Score = {g_best_score:.4f}\")\n",
    "    \n",
    "    return g_best_position, g_best_score\n",
    "\n",
    "# Chạy PSO\n",
    "print(\"🚀 Chạy PSO để tìm siêu tham số tối ưu...\")\n",
    "best_particle, best_score = run_pso_cnn(num_particles=10, max_iter=15)\n",
    "best_params = decode_particle(best_particle)\n",
    "print(f\"🏆 Siêu tham số tốt nhất: {best_params}\")\n",
    "print(f\"📉 Score tốt nhất: {best_score:.4f}\")\n",
    "\n",
    "# Huấn luyện mô hình tối ưu\n",
    "model_optimal = build_cnn_model(**{k: v for k, v in best_params.items() if k != 'batch_size' and k != 'epochs'})\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "rmse_scores_optimal = []\n",
    "history = None\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_train)):\n",
    "    print(f\"\\n📂 Fold {fold + 1}/5\")\n",
    "    X_tr, X_val = X_train[train_idx], X_train[val_idx]\n",
    "    y_tr, y_val = y_train[train_idx], y_train[val_idx]\n",
    "    \n",
    "    history = model_optimal.fit(X_tr, y_tr, epochs=best_params['epochs'], batch_size=best_params['batch_size'], \n",
    "                            validation_split=0.2, verbose=0, callbacks=[early_stopping, reduce_lr])\n",
    "    y_pred = model_optimal.predict(X_val, verbose=0)\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "    rmse_scores_optimal.append(rmse)\n",
    "    print(f\"✅ Fold {fold + 1} RMSE: {rmse:.4f}\")\n",
    "\n",
    "print(f\"\\n📊 RMSE trung bình qua 5 folds: {np.mean(rmse_scores_optimal):.4f}\")\n",
    "\n",
    "# Đánh giá trên tập test\n",
    "y_pred = model_optimal.predict(X_test, verbose=0).flatten()\n",
    "\n",
    "# Tính các chỉ số đánh giá trên giá trị đã scale\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mape = calculate_mape(y_test, y_pred)\n",
    "mmre = calculate_mmre(y_test, y_pred)\n",
    "mdmre = calculate_mdmre(y_test, y_pred)\n",
    "pred25 = calculate_pred25(y_test, y_pred)\n",
    "\n",
    "# Đánh giá bootstrap\n",
    "n_bootstraps = 500\n",
    "bootstrap_metrics = {'mse': [], 'mae': [], 'r2': [], 'mape': [], 'mmre': [], 'mdmre': [], 'pred25': []}\n",
    "\n",
    "for _ in range(n_bootstraps):\n",
    "    indices = np.random.choice(len(y_test), len(y_test), replace=True)\n",
    "    y_test_boot = y_test[indices]\n",
    "    y_pred_boot = y_pred[indices]\n",
    "    bootstrap_metrics['mse'].append(mean_squared_error(y_test_boot, y_pred_boot))\n",
    "    bootstrap_metrics['mae'].append(mean_absolute_error(y_test_boot, y_pred_boot))\n",
    "    bootstrap_metrics['r2'].append(r2_score(y_test_boot, y_pred_boot))\n",
    "    bootstrap_metrics['mape'].append(calculate_mape(y_test_boot, y_pred_boot))\n",
    "    bootstrap_metrics['mmre'].append(calculate_mmre(y_test_boot, y_pred_boot))\n",
    "    bootstrap_metrics['mdmre'].append(calculate_mdmre(y_test_boot, y_pred_boot))\n",
    "    bootstrap_metrics['pred25'].append(calculate_pred25(y_test_boot, y_pred_boot))\n",
    "\n",
    "# In kết quả\n",
    "print(\"\\n📈 Kết quả đánh giá bootstrap (trên giá trị đã scale):\")\n",
    "print(f\"📌 MSE     : {np.mean(bootstrap_metrics['mse']):.4f} ± {np.std(bootstrap_metrics['mse']):.4f}\")\n",
    "print(f\"📌 RMSE    : {np.mean(np.sqrt(bootstrap_metrics['mse'])):.4f} ± {np.std(np.sqrt(bootstrap_metrics['mse'])):.4f}\")\n",
    "print(f\"📌 MAE     : {np.mean(bootstrap_metrics['mae']):.4f} ± {np.std(bootstrap_metrics['mae']):.4f}\")\n",
    "print(f\"📌 R²      : {np.mean(bootstrap_metrics['r2']):.4f} ± {np.std(bootstrap_metrics['r2']):.4f}\")\n",
    "print(f\"📌 MAPE    : {np.mean(bootstrap_metrics['mape']):.2f}% ± {np.std(bootstrap_metrics['mape']):.2f}%\")\n",
    "print(f\"📌 MMRE    : {np.mean(bootstrap_metrics['mmre']):.4f} ± {np.std(bootstrap_metrics['mmre']):.4f}\")\n",
    "print(f\"📌 MdMRE   : {np.mean(bootstrap_metrics['mdmre']):.4f} ± {np.std(bootstrap_metrics['mdmre']):.4f}\")\n",
    "print(f\"📌 PRED(25): {np.mean(bootstrap_metrics['pred25']):.2f}% ± {np.std(bootstrap_metrics['pred25']):.2f}%\")\n",
    "\n",
    "# Lưu kết quả đánh giá\n",
    "results = {\n",
    "    'MSE': mse,\n",
    "    'RMSE': rmse,\n",
    "    'MAE': mae,\n",
    "    'R2': r2,\n",
    "    'MAPE': mape,\n",
    "    'MMRE': mmre,\n",
    "    'MdMRE': mdmre,\n",
    "    'PRED(25)': pred25,\n",
    "    'Bootstrap_MSE_Mean': np.mean(bootstrap_metrics['mse']),\n",
    "    'Bootstrap_MSE_Std': np.std(bootstrap_metrics['mse']),\n",
    "    'Bootstrap_MAE_Mean': np.mean(bootstrap_metrics['mae']),\n",
    "    'Bootstrap_MAE_Std': np.std(bootstrap_metrics['mae']),\n",
    "    'Bootstrap_R2_Mean': np.mean(bootstrap_metrics['r2']),\n",
    "    'Bootstrap_R2_Std': np.std(bootstrap_metrics['r2']),\n",
    "    'Bootstrap_MAPE_Mean': np.mean(bootstrap_metrics['mape']),\n",
    "    'Bootstrap_MAPE_Std': np.std(bootstrap_metrics['mape']),\n",
    "    'Bootstrap_MMRE_Mean': np.mean(bootstrap_metrics['mmre']),\n",
    "    'Bootstrap_MMRE_Std': np.std(bootstrap_metrics['mmre']),\n",
    "    'Bootstrap_MdMRE_Mean': np.mean(bootstrap_metrics['mdmre']),\n",
    "    'Bootstrap_MdMRE_Std': np.std(bootstrap_metrics['mdmre']),\n",
    "    'Bootstrap_PRED25_Mean': np.mean(bootstrap_metrics['pred25']),\n",
    "    'Bootstrap_PRED25_Std': np.std(bootstrap_metrics['pred25'])\n",
    "}\n",
    "\n",
    "results_df = pd.DataFrame([results])\n",
    "results_df.to_csv('cnn_evaluation_results_scaled.csv', index=False)\n",
    "print(\"\\nĐã lưu kết quả đánh giá vào 'cnn_evaluation_results_scaled.csv'\")\n",
    "\n",
    "# Trực quan hóa kết quả\n",
    "plt.figure(figsize=(15, 12))\n",
    "\n",
    "# Loss\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Huber Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Predicted vs Actual\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "plt.title('Predicted vs Actual Effort (Scaled)')\n",
    "plt.xlabel('Actual Effort (Scaled)')\n",
    "plt.ylabel('Predicted Effort (Scaled)')\n",
    "\n",
    "# Error Distribution\n",
    "errors = y_test - y_pred\n",
    "plt.subplot(2, 2, 3)\n",
    "sns.histplot(errors, kde=True)\n",
    "plt.title('Error Distribution')\n",
    "plt.xlabel('Prediction Error (Scaled)')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Bootstrap RMSE\n",
    "plt.subplot(2, 2, 4)\n",
    "sns.boxplot(y=np.sqrt(bootstrap_metrics['mse']))\n",
    "plt.title('Bootstrap RMSE Distribution (Scaled)')\n",
    "plt.ylabel('RMSE (Scaled)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('cnn_visualization_results_scaled.png')\n",
    "plt.close()\n",
    "print(\"\\nĐã lưu hình ảnh trực quan hóa vào 'cnn_visualization_results_scaled.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562d4d71",
   "metadata": {},
   "source": [
    "# MLP\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26b887e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Kiểm tra dữ liệu ===\n",
      "Kích thước: (24, 7)\n",
      "Các cột: ['Input', 'Output', 'Inquiry', 'File', 'FPAdj', 'RawFPcounts', 'Effort']\n",
      "Mẫu 5 hàng đầu tiên:\n",
      "      Input    Output   Inquiry      File     FPAdj  RawFPcounts    Effort\n",
      "0 -0.544978  2.676655  2.425098  2.235928  0.078752     2.030029  1.905014\n",
      "1  2.060336  1.583672  2.425098  1.423982  0.078752     2.030029  1.905014\n",
      "2  1.835512 -0.602296 -1.141891 -0.347538 -1.433293    -0.158757 -0.364603\n",
      "3  0.248519  0.413717  0.417448 -0.347538  1.212786     0.236318  0.476385\n",
      "4 -1.338474  0.690812 -1.063924 -0.568978 -0.677270    -0.336098  1.123946\n",
      "\n",
      "Thông tin dữ liệu:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24 entries, 0 to 23\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Input        24 non-null     float64\n",
      " 1   Output       24 non-null     float64\n",
      " 2   Inquiry      24 non-null     float64\n",
      " 3   File         24 non-null     float64\n",
      " 4   FPAdj        24 non-null     float64\n",
      " 5   RawFPcounts  24 non-null     float64\n",
      " 6   Effort       24 non-null     float64\n",
      "dtypes: float64(7)\n",
      "memory usage: 1.4 KB\n",
      "None\n",
      "\n",
      "=== Sau khi tăng cường dữ liệu bằng nhiễu Gaussian ===\n",
      "X_augmented shape: (72, 6)\n",
      "y_augmented shape: (72,)\n",
      "\n",
      "=== Kích thước dữ liệu sau tăng cường ===\n",
      "X_augmented shape: (72, 6)\n",
      "y_augmented shape: (72,)\n",
      "\n",
      "✅ Kích thước dữ liệu MLP:\n",
      " - X_train: (61, 6)\n",
      " - X_test : (11, 6)\n",
      "🚀 Chạy PSO để tìm siêu tham số tối ưu...\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001C9615CBCE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001C9615CBCE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "🔁 Iteration 1/15\n",
      "✅ Cập nhật g_best: Score = 0.3824\n",
      "✅ Cập nhật g_best: Score = 0.3399\n",
      "✅ Cập nhật g_best: Score = 0.3362\n",
      "\n",
      "🔁 Iteration 2/15\n",
      "✅ Cập nhật g_best: Score = 0.3328\n",
      "\n",
      "🔁 Iteration 3/15\n",
      "✅ Cập nhật g_best: Score = 0.2811\n",
      "\n",
      "🔁 Iteration 4/15\n",
      "\n",
      "🔁 Iteration 5/15\n",
      "\n",
      "🔁 Iteration 6/15\n",
      "\n",
      "🔁 Iteration 7/15\n",
      "\n",
      "🔁 Iteration 8/15\n",
      "✅ Cập nhật g_best: Score = 0.2790\n",
      "\n",
      "🔁 Iteration 9/15\n",
      "\n",
      "🔁 Iteration 10/15\n",
      "\n",
      "🔁 Iteration 11/15\n",
      "\n",
      "🔁 Iteration 12/15\n",
      "\n",
      "🔁 Iteration 13/15\n",
      "\n",
      "🔁 Iteration 14/15\n",
      "✅ Cập nhật g_best: Score = 0.2718\n",
      "\n",
      "🔁 Iteration 15/15\n",
      "🏆 Siêu tham số tốt nhất: {'hidden_layers': 4, 'units_per_layer': 29, 'l2_reg': 0.1, 'dropout_rate': np.float64(0.1783543972687098), 'learning_rate': np.float64(0.0007720671085637227), 'batch_size': 3, 'epochs': 186}\n",
      "📉 Score tốt nhất: 0.2718\n",
      "\n",
      "📂 Fold 1/5\n",
      "✅ Fold 1 RMSE: 0.8441\n",
      "\n",
      "📂 Fold 2/5\n",
      "✅ Fold 2 RMSE: 0.7190\n",
      "\n",
      "📂 Fold 3/5\n",
      "✅ Fold 3 RMSE: 0.4486\n",
      "\n",
      "📂 Fold 4/5\n",
      "✅ Fold 4 RMSE: 0.4940\n",
      "\n",
      "📂 Fold 5/5\n",
      "✅ Fold 5 RMSE: 0.7034\n",
      "\n",
      "📊 RMSE trung bình qua 5 folds: 0.6418\n",
      "\n",
      "📈 Kết quả đánh giá bootstrap (trên giá trị đã scale):\n",
      "📌 MSE     : 0.3518 ± 0.1210\n",
      "📌 RMSE    : 0.5839 ± 0.1042\n",
      "📌 MAE     : 0.4875 ± 0.1032\n",
      "📌 R²      : 0.5432 ± 0.8945\n",
      "📌 MAPE    : 64.86% ± 15.23%\n",
      "📌 MMRE    : 0.6486 ± 0.1523\n",
      "📌 MdMRE   : 0.5745 ± 0.2262\n",
      "📌 PRED(25): 27.49% ± 13.68%\n",
      "\n",
      "Đã lưu kết quả đánh giá vào 'mlp_evaluation_results_scaled.csv'\n",
      "\n",
      "Đã lưu hình ảnh trực quan hóa vào 'mlp_visualization_results_scaled.png'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from uuid import uuid4\n",
    "\n",
    "# Thiết lập seed để tái lập\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Hàm tính các chỉ số đánh giá\n",
    "def calculate_mape(y_true, y_pred):\n",
    "    mask = y_true != 0\n",
    "    if np.sum(mask) == 0:\n",
    "        return np.nan\n",
    "    return np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100\n",
    "\n",
    "def calculate_mmre(y_true, y_pred):\n",
    "    mask = y_true != 0\n",
    "    if np.sum(mask) == 0:\n",
    "        return np.nan\n",
    "    return np.mean(np.abs(((y_true[mask] - y_pred[mask]) / y_true[mask])))\n",
    "\n",
    "def calculate_mdmre(y_true, y_pred):\n",
    "    mask = y_true != 0\n",
    "    if np.sum(mask) == 0:\n",
    "        return np.nan\n",
    "    return np.median(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask]))\n",
    "\n",
    "def calculate_pred25(y_true, y_pred):\n",
    "    mask = y_true != 0\n",
    "    if np.sum(mask) == 0:\n",
    "        return np.nan\n",
    "    mre = np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])\n",
    "    return np.mean(mre <= 0.25) * 100\n",
    "\n",
    "# Đọc dữ liệu đã tiền xử lý\n",
    "df = pd.read_csv('albrecht_cleaned.csv')\n",
    "\n",
    "# Kiểm tra dữ liệu\n",
    "print(\"=== Kiểm tra dữ liệu ===\")\n",
    "print(\"Kích thước:\", df.shape)\n",
    "print(\"Các cột:\", df.columns.tolist())\n",
    "print(\"Mẫu 5 hàng đầu tiên:\")\n",
    "print(df.head())\n",
    "print(\"\\nThông tin dữ liệu:\")\n",
    "print(df.info())\n",
    "\n",
    "# Chọn đặc trưng và biến mục tiêu\n",
    "features = [col for col in df.columns if col not in ['Project', 'Effort', 'Effort_log']]\n",
    "X = df[features].values\n",
    "y = df['Effort'].values  # Sử dụng Effort đã được scale từ file test.csv\n",
    "\n",
    "# Tăng cường dữ liệu bằng nhiễu Gaussian\n",
    "def add_gaussian_noise(X, noise_factor=0.05):\n",
    "    noise = np.random.normal(loc=0, scale=noise_factor, size=X.shape)\n",
    "    return X + noise\n",
    "\n",
    "X_augmented = X.copy()\n",
    "y_augmented = y.copy()\n",
    "for _ in range(2):  # Tạo thêm 2 bản sao với nhiễu\n",
    "    X_noisy = add_gaussian_noise(X, noise_factor=0.05)\n",
    "    X_augmented = np.vstack((X_augmented, X_noisy))\n",
    "    y_augmented = np.hstack((y_augmented, y))\n",
    "\n",
    "print(\"\\n=== Sau khi tăng cường dữ liệu bằng nhiễu Gaussian ===\")\n",
    "print(\"X_augmented shape:\", X_augmented.shape)\n",
    "print(\"y_augmented shape:\", y_augmented.shape)\n",
    "\n",
    "# Không cần reshape cho MLP vì MLP không yêu cầu dữ liệu 3D\n",
    "print(\"\\n=== Kích thước dữ liệu sau tăng cường ===\")\n",
    "print(\"X_augmented shape:\", X_augmented.shape)\n",
    "print(\"y_augmented shape:\", y_augmented.shape)\n",
    "\n",
    "# Chia tập train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_augmented, y_augmented, test_size=0.15, random_state=42)\n",
    "\n",
    "print(f\"\\n✅ Kích thước dữ liệu MLP:\")\n",
    "print(f\" - X_train: {X_train.shape}\")\n",
    "print(f\" - X_test : {X_test.shape}\")\n",
    "\n",
    "# Xây dựng mô hình MLP với Dense, BatchNormalization, Dropout\n",
    "def build_mlp_model(hidden_layers=2, units_per_layer=32, l2_reg=0.01, dropout_rate=0.3, learning_rate=0.001):\n",
    "    # Đảm bảo l2_reg không âm\n",
    "    l2_reg = max(l2_reg, 0.001)\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(X_train.shape[1],)))\n",
    "    \n",
    "    # Thêm các tầng ẩn\n",
    "    for _ in range(int(hidden_layers)):\n",
    "        model.add(Dense(int(units_per_layer), activation='relu', kernel_regularizer=l2(l2_reg)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    # Tầng đầu ra\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    \n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss=tf.keras.losses.Huber(), metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# Không gian siêu tham số cho MLP\n",
    "param_bounds = {\n",
    "    'hidden_layers': (1, 4),  # Số tầng ẩn\n",
    "    'units_per_layer': (16, 128),  # Số đơn vị mỗi tầng\n",
    "    'l2_reg': (0.001, 0.1),\n",
    "    'dropout_rate': (0.2, 0.5),\n",
    "    'learning_rate': (1e-4, 1e-2),\n",
    "    'batch_size': (16, 64),\n",
    "    'epochs': (50, 150)\n",
    "}\n",
    "\n",
    "# Hàm mã hóa & giải mã particle\n",
    "def random_particle():\n",
    "    return np.array([\n",
    "        np.random.randint(param_bounds['hidden_layers'][0], param_bounds['hidden_layers'][1] + 1),\n",
    "        np.random.randint(param_bounds['units_per_layer'][0], param_bounds['units_per_layer'][1] + 1),\n",
    "        np.random.uniform(param_bounds['l2_reg'][0], param_bounds['l2_reg'][1]),\n",
    "        np.random.uniform(param_bounds['dropout_rate'][0], param_bounds['dropout_rate'][1]),\n",
    "        np.random.uniform(param_bounds['learning_rate'][0], param_bounds['learning_rate'][1]),\n",
    "        np.random.randint(param_bounds['batch_size'][0], param_bounds['batch_size'][1] + 1),\n",
    "        np.random.randint(param_bounds['epochs'][0], param_bounds['epochs'][1] + 1)\n",
    "    ])\n",
    "\n",
    "def decode_particle(particle):\n",
    "    params = {\n",
    "        'hidden_layers': int(particle[0]),\n",
    "        'units_per_layer': int(particle[1]),\n",
    "        'l2_reg': particle[2],\n",
    "        'dropout_rate': particle[3],\n",
    "        'learning_rate': particle[4],\n",
    "        'batch_size': int(particle[5]),\n",
    "        'epochs': int(particle[6])\n",
    "    }\n",
    "    # Đảm bảo l2_reg không âm\n",
    "    params['l2_reg'] = max(params['l2_reg'], 0.001)\n",
    "    params['l2_reg'] = min(params['l2_reg'], param_bounds['l2_reg'][1])\n",
    "    return params\n",
    "\n",
    "# Hàm fitness cho PSO\n",
    "def fitness_function(particle):\n",
    "    params = decode_particle(particle)\n",
    "    model = build_mlp_model(**{k: v for k, v in params.items() if k != 'batch_size' and k != 'epochs'})\n",
    "    \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    rmse_scores = []\n",
    "    \n",
    "    for train_idx, val_idx in kf.split(X_train):\n",
    "        X_tr, X_val = X_train[train_idx], X_train[val_idx]\n",
    "        y_tr, y_val = y_train[train_idx], y_train[val_idx]\n",
    "        \n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
    "        reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
    "        \n",
    "        model.fit(X_tr, y_tr, epochs=params['epochs'], batch_size=params['batch_size'], \n",
    "                  validation_split=0.2, verbose=0, callbacks=[early_stopping, reduce_lr])\n",
    "        y_pred = model.predict(X_val, verbose=0)\n",
    "        rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "        rmse_scores.append(rmse)\n",
    "    \n",
    "    return np.mean(rmse_scores)\n",
    "\n",
    "# Triển khai PSO\n",
    "def run_pso_mlp(num_particles=10, max_iter=10):\n",
    "    dim = len(param_bounds)\n",
    "    bounds_array = np.array(list(param_bounds.values()))\n",
    "    \n",
    "    particles = [random_particle() for _ in range(num_particles)]\n",
    "    velocities = [np.zeros(dim) for _ in range(num_particles)]\n",
    "    \n",
    "    p_best_positions = particles.copy()\n",
    "    p_best_scores = [fitness_function(p) for p in particles]\n",
    "    \n",
    "    g_best_index = np.argmin(p_best_scores)\n",
    "    g_best_position = p_best_positions[g_best_index]\n",
    "    g_best_score = p_best_scores[g_best_index]\n",
    "    \n",
    "    w, c1, c2 = 0.5, 1.5, 1.5\n",
    "    \n",
    "    for iter in range(max_iter):\n",
    "        print(f\"\\n🔁 Iteration {iter + 1}/{max_iter}\")\n",
    "        for i in range(num_particles):\n",
    "            r1 = np.random.rand(dim)\n",
    "            r2 = np.random.rand(dim)\n",
    "            \n",
    "            velocities[i] = (\n",
    "                w * velocities[i]\n",
    "                + c1 * r1 * (p_best_positions[i] - particles[i])\n",
    "                + c2 * r2 * (g_best_position - particles[i])\n",
    "            )\n",
    "            \n",
    "            particles[i] += velocities[i]\n",
    "            particles[i] = np.clip(particles[i], bounds_array[:, 0], bounds_array[:, 1])\n",
    "            # Đảm bảo l2_reg không âm và trong giới hạn\n",
    "            particles[i][2] = max(particles[i][2], param_bounds['l2_reg'][0])\n",
    "            particles[i][2] = min(particles[i][2], param_bounds['l2_reg'][1])\n",
    "            particles[i][3] = np.clip(particles[i][3], param_bounds['dropout_rate'][0], param_bounds['dropout_rate'][1])\n",
    "            \n",
    "            score = fitness_function(particles[i])\n",
    "            \n",
    "            if score < p_best_scores[i]:\n",
    "                p_best_scores[i] = score\n",
    "                p_best_positions[i] = particles[i]\n",
    "                \n",
    "            if score < g_best_score:\n",
    "                g_best_score = score\n",
    "                g_best_position = particles[i]\n",
    "                print(f\"✅ Cập nhật g_best: Score = {g_best_score:.4f}\")\n",
    "    \n",
    "    return g_best_position, g_best_score\n",
    "\n",
    "# Chạy PSO\n",
    "print(\"🚀 Chạy PSO để tìm siêu tham số tối ưu...\")\n",
    "best_particle, best_score = run_pso_mlp()\n",
    "best_params = decode_particle(best_particle)\n",
    "print(f\"🏆 Siêu tham số tốt nhất: {best_params}\")\n",
    "print(f\"📉 Score tốt nhất: {best_score:.4f}\")\n",
    "\n",
    "# Huấn luyện mô hình tối ưu\n",
    "model_optimal = build_mlp_model(**{k: v for k, v in best_params.items() if k != 'batch_size' and k != 'epochs'})\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "rmse_scores_optimal = []\n",
    "history = None\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_train)):\n",
    "    print(f\"\\n📂 Fold {fold + 1}/5\")\n",
    "    X_tr, X_val = X_train[train_idx], X_train[val_idx]\n",
    "    y_tr, y_val = y_train[train_idx], y_train[val_idx]\n",
    "    \n",
    "    history = model_optimal.fit(X_tr, y_tr, epochs=best_params['epochs'], batch_size=best_params['batch_size'], \n",
    "                               validation_split=0.2, verbose=0, callbacks=[early_stopping, reduce_lr])\n",
    "    y_pred = model_optimal.predict(X_val, verbose=0)\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "    rmse_scores_optimal.append(rmse)\n",
    "    print(f\"✅ Fold {fold + 1} RMSE: {rmse:.4f}\")\n",
    "\n",
    "print(f\"\\n📊 RMSE trung bình qua 5 folds: {np.mean(rmse_scores_optimal):.4f}\")\n",
    "\n",
    "# Đánh giá trên tập test\n",
    "y_pred = model_optimal.predict(X_test, verbose=0).flatten()\n",
    "\n",
    "# Tính các chỉ số đánh giá trên giá trị đã scale\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mape = calculate_mape(y_test, y_pred)\n",
    "mmre = calculate_mmre(y_test, y_pred)\n",
    "mdmre = calculate_mdmre(y_test, y_pred)\n",
    "pred25 = calculate_pred25(y_test, y_pred)\n",
    "\n",
    "# Đánh giá bootstrap\n",
    "n_bootstraps = 500\n",
    "bootstrap_metrics = {'mse': [], 'mae': [], 'r2': [], 'mape': [], 'mmre': [], 'mdmre': [], 'pred25': []}\n",
    "\n",
    "for _ in range(n_bootstraps):\n",
    "    indices = np.random.choice(len(y_test), len(y_test), replace=True)\n",
    "    y_test_boot = y_test[indices]\n",
    "    y_pred_boot = y_pred[indices]\n",
    "    bootstrap_metrics['mse'].append(mean_squared_error(y_test_boot, y_pred_boot))\n",
    "    bootstrap_metrics['mae'].append(mean_absolute_error(y_test_boot, y_pred_boot))\n",
    "    bootstrap_metrics['r2'].append(r2_score(y_test_boot, y_pred_boot))\n",
    "    bootstrap_metrics['mape'].append(calculate_mape(y_test_boot, y_pred_boot))\n",
    "    bootstrap_metrics['mmre'].append(calculate_mmre(y_test_boot, y_pred_boot))\n",
    "    bootstrap_metrics['mdmre'].append(calculate_mdmre(y_test_boot, y_pred_boot))\n",
    "    bootstrap_metrics['pred25'].append(calculate_pred25(y_test_boot, y_pred_boot))\n",
    "\n",
    "# In kết quả\n",
    "print(\"\\n📈 Kết quả đánh giá bootstrap (trên giá trị đã scale):\")\n",
    "print(f\"📌 MSE     : {np.mean(bootstrap_metrics['mse']):.4f} ± {np.std(bootstrap_metrics['mse']):.4f}\")\n",
    "print(f\"📌 RMSE    : {np.mean(np.sqrt(bootstrap_metrics['mse'])):.4f} ± {np.std(np.sqrt(bootstrap_metrics['mse'])):.4f}\")\n",
    "print(f\"📌 MAE     : {np.mean(bootstrap_metrics['mae']):.4f} ± {np.std(bootstrap_metrics['mae']):.4f}\")\n",
    "print(f\"📌 R²      : {np.mean(bootstrap_metrics['r2']):.4f} ± {np.std(bootstrap_metrics['r2']):.4f}\")\n",
    "print(f\"📌 MAPE    : {np.mean(bootstrap_metrics['mape']):.2f}% ± {np.std(bootstrap_metrics['mape']):.2f}%\")\n",
    "print(f\"📌 MMRE    : {np.mean(bootstrap_metrics['mmre']):.4f} ± {np.std(bootstrap_metrics['mmre']):.4f}\")\n",
    "print(f\"📌 MdMRE   : {np.mean(bootstrap_metrics['mdmre']):.4f} ± {np.std(bootstrap_metrics['mdmre']):.4f}\")\n",
    "print(f\"📌 PRED(25): {np.mean(bootstrap_metrics['pred25']):.2f}% ± {np.std(bootstrap_metrics['pred25']):.2f}%\")\n",
    "\n",
    "# Lưu kết quả đánh giá\n",
    "results = {\n",
    "    'MSE': mse,\n",
    "    'RMSE': rmse,\n",
    "    'MAE': mae,\n",
    "    'R2': r2,\n",
    "    'MAPE': mape,\n",
    "    'MMRE': mmre,\n",
    "    'MdMRE': mdmre,\n",
    "    'PRED(25)': pred25,\n",
    "    'Bootstrap_MSE_Mean': np.mean(bootstrap_metrics['mse']),\n",
    "    'Bootstrap_MSE_Std': np.std(bootstrap_metrics['mse']),\n",
    "    'Bootstrap_MAE_Mean': np.mean(bootstrap_metrics['mae']),\n",
    "    'Bootstrap_MAE_Std': np.std(bootstrap_metrics['mae']),\n",
    "    'Bootstrap_R2_Mean': np.mean(bootstrap_metrics['r2']),\n",
    "    'Bootstrap_R2_Std': np.std(bootstrap_metrics['r2']),\n",
    "    'Bootstrap_MAPE_Mean': np.mean(bootstrap_metrics['mape']),\n",
    "    'Bootstrap_MAPE_Std': np.std(bootstrap_metrics['mape']),\n",
    "    'Bootstrap_MMRE_Mean': np.mean(bootstrap_metrics['mmre']),\n",
    "    'Bootstrap_MMRE_Std': np.std(bootstrap_metrics['mmre']),\n",
    "    'Bootstrap_MdMRE_Mean': np.mean(bootstrap_metrics['mdmre']),\n",
    "    'Bootstrap_MdMRE_Std': np.std(bootstrap_metrics['mdmre']),\n",
    "    'Bootstrap_PRED25_Mean': np.mean(bootstrap_metrics['pred25']),\n",
    "    'Bootstrap_PRED25_Std': np.std(bootstrap_metrics['pred25'])\n",
    "}\n",
    "\n",
    "results_df = pd.DataFrame([results])\n",
    "results_df.to_csv('mlp_evaluation_results_scaled.csv', index=False)\n",
    "print(\"\\nĐã lưu kết quả đánh giá vào 'mlp_evaluation_results_scaled.csv'\")\n",
    "\n",
    "# Trực quan hóa kết quả\n",
    "plt.figure(figsize=(15, 12))\n",
    "\n",
    "# Loss\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Huber Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Predicted vs Actual\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "plt.title('Predicted vs Actual Effort (Scaled)')\n",
    "plt.xlabel('Actual Effort (Scaled)')\n",
    "plt.ylabel('Predicted Effort (Scaled)')\n",
    "\n",
    "# Error Distribution\n",
    "errors = y_test - y_pred\n",
    "plt.subplot(2, 2, 3)\n",
    "sns.histplot(errors, kde=True)\n",
    "plt.title('Error Distribution')\n",
    "plt.xlabel('Prediction Error (Scaled)')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Bootstrap RMSE\n",
    "plt.subplot(2, 2, 4)\n",
    "sns.boxplot(y=np.sqrt(bootstrap_metrics['mse']))\n",
    "plt.title('Bootstrap RMSE Distribution (Scaled)')\n",
    "plt.ylabel('RMSE (Scaled)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('mlp_visualization_results_scaled.png')\n",
    "plt.close()\n",
    "print(\"\\nĐã lưu hình ảnh trực quan hóa vào 'mlp_visualization_results_scaled.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce20d50",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebf29e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Kiểm tra dữ liệu ===\n",
      "Kích thước ban đầu: (24, 7)\n",
      "Các cột: ['Input', 'Output', 'Inquiry', 'File', 'FPAdj', 'RawFPcounts', 'Effort']\n",
      "Mẫu 5 hàng đầu tiên:\n",
      "      Input    Output   Inquiry      File     FPAdj  RawFPcounts    Effort\n",
      "0 -0.544978  2.676655  2.425098  2.235928  0.078752     2.030029  1.905014\n",
      "1  2.060336  1.583672  2.425098  1.423982  0.078752     2.030029  1.905014\n",
      "2  1.835512 -0.602296 -1.141891 -0.347538 -1.433293    -0.158757 -0.364603\n",
      "3  0.248519  0.413717  0.417448 -0.347538  1.212786     0.236318  0.476385\n",
      "4 -1.338474  0.690812 -1.063924 -0.568978 -0.677270    -0.336098  1.123946\n",
      "\n",
      "=== Kích thước dữ liệu sau tăng cường và reshape ===\n",
      "X_augmented shape: (72, 1, 6)\n",
      "y_augmented shape: (72,)\n",
      "\n",
      "✅ Kích thước dữ liệu LSTM:\n",
      " - X_train: (57, 1, 6)\n",
      " - X_test : (15, 1, 6)\n",
      "🚀 Chạy PSO để tìm siêu tham số tối ưu...\n",
      "\n",
      "🔁 Iteration 1/15\n",
      "✅ Cập nhật g_best: PRED(25) = 77.2727%\n",
      "✅ Cập nhật g_best: PRED(25) = 80.9091%\n",
      "\n",
      "🔁 Iteration 2/15\n",
      "✅ Cập nhật g_best: PRED(25) = 82.8788%\n",
      "\n",
      "🔁 Iteration 3/15\n",
      "✅ Cập nhật g_best: PRED(25) = 86.2121%\n",
      "\n",
      "🔁 Iteration 4/15\n",
      "\n",
      "🔁 Iteration 5/15\n",
      "\n",
      "🔁 Iteration 6/15\n",
      "\n",
      "🔁 Iteration 7/15\n",
      "\n",
      "🔁 Iteration 8/15\n",
      "\n",
      "🔁 Iteration 9/15\n",
      "\n",
      "🔁 Iteration 10/15\n",
      "\n",
      "🔁 Iteration 11/15\n",
      "\n",
      "🔁 Iteration 12/15\n",
      "\n",
      "🔁 Iteration 13/15\n",
      "\n",
      "🔁 Iteration 14/15\n",
      "\n",
      "🔁 Iteration 15/15\n",
      "🏆 Siêu tham số tốt nhất: {'units': 59, 'dropout_rate': np.float64(0.250012773027689), 'learning_rate': np.float64(0.01175980209993104), 'batch_size': 2, 'epochs': 45}\n",
      "📉 PRED(25) tốt nhất: 86.2121%\n",
      "\n",
      "📂 Fold 1/5\n",
      "✅ Fold 1 PRED(25): 41.6667%\n",
      "\n",
      "📂 Fold 2/5\n",
      "✅ Fold 2 PRED(25): 41.6667%\n",
      "\n",
      "📂 Fold 3/5\n",
      "✅ Fold 3 PRED(25): 54.5455%\n",
      "\n",
      "📂 Fold 4/5\n",
      "✅ Fold 4 PRED(25): 63.6364%\n",
      "\n",
      "📂 Fold 5/5\n",
      "✅ Fold 5 PRED(25): 54.5455%\n",
      "\n",
      "📊 PRED(25) trung bình qua 5 folds: 51.2121%\n",
      "\n",
      "📈 Kết quả đánh giá bootstrap (thang gốc):\n",
      "📌 MSE     : 0.0287 ± 0.0103\n",
      "📌 RMSE    : 0.1667 ± 0.0308\n",
      "📌 MAE     : 0.1339 ± 0.0270\n",
      "📌 R²      : 0.9621 ± 0.0205\n",
      "📌 MAPE    : 24.42% ± 6.42%\n",
      "📌 MMRE    : 0.2442 ± 0.0642\n",
      "📌 MdMRE   : 0.1331 ± 0.0566\n",
      "📌 PRED(25): 72.55% ± 11.22%\n",
      "\n",
      "Đã lưu kết quả đánh giá vào 'lstm_evaluation_results.csv'\n",
      "\n",
      "Đã lưu hình ảnh trực quan hóa vào 'lstm_visualization_results.png'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Thiết lập seed để tái lập\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Hàm tính các chỉ số đánh giá\n",
    "def calculate_mape(y_true, y_pred):\n",
    "    mask = y_true != 0\n",
    "    if np.sum(mask) == 0:\n",
    "        return np.nan\n",
    "    return np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100\n",
    "\n",
    "def calculate_mmre(y_true, y_pred):\n",
    "    mask = y_true != 0\n",
    "    if np.sum(mask) == 0:\n",
    "        return np.nan\n",
    "    return np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask]))\n",
    "\n",
    "def calculate_mdmre(y_true, y_pred):\n",
    "    mask = y_true != 0\n",
    "    if np.sum(mask) == 0:\n",
    "        return np.nan\n",
    "    return np.median(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask]))\n",
    "\n",
    "def calculate_pred25(y_true, y_pred):\n",
    "    mask = y_true != 0\n",
    "    if np.sum(mask) == 0:\n",
    "        return np.nan\n",
    "    mre = np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])\n",
    "    return np.mean(mre <= 0.25) * 100\n",
    "\n",
    "# Tăng cường dữ liệu bằng nhiễu Gaussian\n",
    "def add_gaussian_noise(X, y, noise_factor=0.01):\n",
    "    X_noise = X + np.random.normal(loc=0, scale=noise_factor * np.std(X, axis=0), size=X.shape)\n",
    "    y_noise = y + np.random.normal(loc=0, scale=noise_factor * np.std(y), size=y.shape)\n",
    "    return X_noise, y_noise\n",
    "\n",
    "# Đọc dữ liệu\n",
    "df = pd.read_csv('albrecht_cleaned.csv')\n",
    "\n",
    "# Xử lý ngoại lai với RobustScaler\n",
    "feature_scaler = RobustScaler()\n",
    "target_scaler = RobustScaler()\n",
    "features = [col for col in df.columns if col != 'Effort']\n",
    "X = feature_scaler.fit_transform(df[features].values)\n",
    "y = target_scaler.fit_transform(df[['Effort']].values).flatten()\n",
    "\n",
    "# Tăng cường dữ liệu\n",
    "X_augmented = X.copy()\n",
    "y_augmented = y.copy()\n",
    "for _ in range(2):  # Tạo 2 bản sao với nhiễu, tăng từ 24 lên 72 mẫu\n",
    "    X_noise, y_noise = add_gaussian_noise(X, y, noise_factor=0.01)\n",
    "    X_augmented = np.vstack((X_augmented, X_noise))\n",
    "    y_augmented = np.hstack((y_augmented, y_noise))\n",
    "\n",
    "# Reshape dữ liệu cho LSTM: (samples, 1, features)\n",
    "X_augmented = X_augmented.reshape(X_augmented.shape[0], 1, X_augmented.shape[1])\n",
    "\n",
    "print(\"=== Kiểm tra dữ liệu ===\")\n",
    "print(\"Kích thước ban đầu:\", df.shape)\n",
    "print(\"Các cột:\", df.columns.tolist())\n",
    "print(\"Mẫu 5 hàng đầu tiên:\")\n",
    "print(df.head())\n",
    "print(\"\\n=== Kích thước dữ liệu sau tăng cường và reshape ===\")\n",
    "print(\"X_augmented shape:\", X_augmented.shape)\n",
    "print(\"y_augmented shape:\", y_augmented.shape)\n",
    "\n",
    "# Chia tập train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_augmented, y_augmented, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"\\n✅ Kích thước dữ liệu LSTM:\")\n",
    "print(f\" - X_train: {X_train.shape}\")\n",
    "print(f\" - X_test : {X_test.shape}\")\n",
    "\n",
    "# Xây dựng mô hình LSTM đơn giản\n",
    "def build_lstm_model(units=16, dropout_rate=0.1, learning_rate=0.001):\n",
    "    model = Sequential([\n",
    "        Input(shape=(X_train.shape[1], X_train.shape[2])),\n",
    "        LSTM(units, return_sequences=False),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(units // 2, activation='relu'),\n",
    "        Dense(1, activation='linear')\n",
    "    ])\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# Không gian siêu tham số\n",
    "param_bounds = {\n",
    "    'units': (16, 64),\n",
    "    'dropout_rate': (0.0, 0.2),\n",
    "    'learning_rate': (1e-4, 1e-2),\n",
    "    'batch_size': (4, 16),\n",
    "    'epochs': (50, 100)\n",
    "}\n",
    "\n",
    "# Hàm mã hóa & giải mã particle\n",
    "def random_particle():\n",
    "    return np.array([\n",
    "        np.random.randint(param_bounds['units'][0], param_bounds['units'][1] + 1),\n",
    "        np.random.uniform(param_bounds['dropout_rate'][0], param_bounds['dropout_rate'][1]),\n",
    "        np.random.uniform(param_bounds['learning_rate'][0], param_bounds['learning_rate'][1]),\n",
    "        np.random.randint(param_bounds['batch_size'][0], param_bounds['batch_size'][1] + 1),\n",
    "        np.random.randint(param_bounds['epochs'][0], param_bounds['epochs'][1] + 1)\n",
    "    ])\n",
    "\n",
    "def decode_particle(particle):\n",
    "    return {\n",
    "        'units': int(particle[0]),\n",
    "        'dropout_rate': particle[1],\n",
    "        'learning_rate': particle[2],\n",
    "        'batch_size': int(particle[3]),\n",
    "        'epochs': int(particle[4])\n",
    "    }\n",
    "\n",
    "# Hàm fitness cho PSO\n",
    "def fitness_function(particle):\n",
    "    params = decode_particle(particle)\n",
    "    model = build_lstm_model(**{k: v for k, v in params.items() if k != 'batch_size' and k != 'epochs'})\n",
    "    \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    pred25_scores = []\n",
    "    \n",
    "    for train_idx, val_idx in kf.split(X_train):\n",
    "        X_tr, X_val = X_train[train_idx], X_train[val_idx]\n",
    "        y_tr, y_val = y_train[train_idx], y_train[val_idx]\n",
    "        \n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "        reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
    "        \n",
    "        model.fit(X_tr, y_tr, epochs=params['epochs'], batch_size=params['batch_size'], \n",
    "                  validation_data=(X_val, y_val), verbose=0, callbacks=[early_stopping, reduce_lr])\n",
    "        y_pred = model.predict(X_val, verbose=0).flatten()\n",
    "        pred25 = calculate_pred25(y_val, y_pred)\n",
    "        pred25_scores.append(pred25)\n",
    "    \n",
    "    return -np.mean(pred25_scores)  # Tối ưu hóa PRED(25)\n",
    "\n",
    "# Triển khai PSO\n",
    "def run_pso_lstm(num_particles=10, max_iter=15):\n",
    "    dim = len(param_bounds)\n",
    "    bounds_array = np.array(list(param_bounds.values()))\n",
    "    \n",
    "    particles = [random_particle() for _ in range(num_particles)]\n",
    "    velocities = [np.zeros(dim) for _ in range(num_particles)]\n",
    "    \n",
    "    p_best_positions = particles.copy()\n",
    "    p_best_scores = [fitness_function(p) for p in particles]\n",
    "    \n",
    "    g_best_index = np.argmin(p_best_scores)\n",
    "    g_best_position = p_best_positions[g_best_index]\n",
    "    g_best_score = p_best_scores[g_best_index]\n",
    "    \n",
    "    w, c1, c2 = 0.7, 1.4, 1.4\n",
    "    \n",
    "    for iter in range(max_iter):\n",
    "        print(f\"\\n🔁 Iteration {iter + 1}/{max_iter}\")\n",
    "        for i in range(num_particles):\n",
    "            r1 = np.random.rand(dim)\n",
    "            r2 = np.random.rand(dim)\n",
    "            \n",
    "            velocities[i] = (\n",
    "                w * velocities[i]\n",
    "                + c1 * r1 * (p_best_positions[i] - particles[i])\n",
    "                + c2 * r2 * (g_best_position - particles[i])\n",
    "            )\n",
    "            \n",
    "            particles[i] += velocities[i]\n",
    "            particles[i] = np.clip(particles[i], bounds_array[:, 0], bounds_array[:, 1])\n",
    "            \n",
    "            score = fitness_function(particles[i])\n",
    "            \n",
    "            if score < p_best_scores[i]:\n",
    "                p_best_scores[i] = score\n",
    "                p_best_positions[i] = particles[i]\n",
    "                \n",
    "            if score < g_best_score:\n",
    "                g_best_score = score\n",
    "                g_best_position = particles[i]\n",
    "                print(f\"✅ Cập nhật g_best: PRED(25) = {-g_best_score:.4f}%\")\n",
    "    \n",
    "    return g_best_position, g_best_score\n",
    "\n",
    "# Chạy PSO\n",
    "print(\"🚀 Chạy PSO để tìm siêu tham số tối ưu...\")\n",
    "best_particle, best_score = run_pso_lstm(num_particles=10, max_iter=15)\n",
    "best_params = decode_particle(best_particle)\n",
    "print(f\"🏆 Siêu tham số tốt nhất: {best_params}\")\n",
    "print(f\"📉 PRED(25) tốt nhất: {-best_score:.4f}%\")\n",
    "\n",
    "# Huấn luyện mô hình tối ưu\n",
    "model_optimal = build_lstm_model(**{k: v for k, v in best_params.items() if k != 'batch_size' and k != 'epochs'})\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "pred25_scores_optimal = []\n",
    "history = None\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_train)):\n",
    "    print(f\"\\n📂 Fold {fold + 1}/5\")\n",
    "    X_tr, X_val = X_train[train_idx], X_train[val_idx]\n",
    "    y_tr, y_val = y_train[train_idx], y_train[val_idx]\n",
    "    \n",
    "    history = model_optimal.fit(X_tr, y_tr, epochs=best_params['epochs'], batch_size=best_params['batch_size'], \n",
    "                               validation_data=(X_val, y_val), verbose=0, callbacks=[early_stopping, reduce_lr])\n",
    "    y_pred = model_optimal.predict(X_val, verbose=0).flatten()\n",
    "    pred25 = calculate_pred25(y_val, y_pred)\n",
    "    pred25_scores_optimal.append(pred25)\n",
    "    print(f\"✅ Fold {fold + 1} PRED(25): {pred25:.4f}%\")\n",
    "\n",
    "print(f\"\\n📊 PRED(25) trung bình qua 5 folds: {np.mean(pred25_scores_optimal):.4f}%\")\n",
    "\n",
    "# Đánh giá trên tập test\n",
    "y_pred = model_optimal.predict(X_test, verbose=0).flatten()\n",
    "\n",
    "# Chuyển ngược về thang gốc\n",
    "y_test_orig = target_scaler.inverse_transform(y_test.reshape(-1, 1)).flatten()\n",
    "y_pred_orig = target_scaler.inverse_transform(y_pred.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Tính các chỉ số đánh giá\n",
    "mse = mean_squared_error(y_test_orig, y_pred_orig)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test_orig, y_pred_orig)\n",
    "r2 = r2_score(y_test_orig, y_pred_orig)\n",
    "mape = calculate_mape(y_test_orig, y_pred_orig)\n",
    "mmre = calculate_mmre(y_test_orig, y_pred_orig)\n",
    "mdmre = calculate_mdmre(y_test_orig, y_pred_orig)\n",
    "pred25 = calculate_pred25(y_test_orig, y_pred_orig)\n",
    "\n",
    "# Đánh giá bootstrap\n",
    "n_bootstraps = 500\n",
    "bootstrap_metrics = {'mse': [], 'mae': [], 'r2': [], 'mape': [], 'mmre': [], 'mdmre': [], 'pred25': []}\n",
    "\n",
    "for _ in range(n_bootstraps):\n",
    "    indices = np.random.choice(len(y_test_orig), len(y_test_orig), replace=True)\n",
    "    y_test_boot = y_test_orig[indices]\n",
    "    y_pred_boot = y_pred_orig[indices]\n",
    "    bootstrap_metrics['mse'].append(mean_squared_error(y_test_boot, y_pred_boot))\n",
    "    bootstrap_metrics['mae'].append(mean_absolute_error(y_test_boot, y_pred_boot))\n",
    "    bootstrap_metrics['r2'].append(r2_score(y_test_boot, y_pred_boot))\n",
    "    bootstrap_metrics['mape'].append(calculate_mape(y_test_boot, y_pred_boot))\n",
    "    bootstrap_metrics['mmre'].append(calculate_mmre(y_test_boot, y_pred_boot))\n",
    "    bootstrap_metrics['mdmre'].append(calculate_mdmre(y_test_boot, y_pred_boot))\n",
    "    bootstrap_metrics['pred25'].append(calculate_pred25(y_test_boot, y_pred_boot))\n",
    "\n",
    "# In kết quả\n",
    "print(\"\\n📈 Kết quả đánh giá bootstrap (thang gốc):\")\n",
    "print(f\"📌 MSE     : {np.mean(bootstrap_metrics['mse']):.4f} ± {np.std(bootstrap_metrics['mse']):.4f}\")\n",
    "print(f\"📌 RMSE    : {np.mean(np.sqrt(bootstrap_metrics['mse'])):.4f} ± {np.std(np.sqrt(bootstrap_metrics['mse'])):.4f}\")\n",
    "print(f\"📌 MAE     : {np.mean(bootstrap_metrics['mae']):.4f} ± {np.std(bootstrap_metrics['mae']):.4f}\")\n",
    "print(f\"📌 R²      : {np.mean(bootstrap_metrics['r2']):.4f} ± {np.std(bootstrap_metrics['r2']):.4f}\")\n",
    "print(f\"📌 MAPE    : {np.mean(bootstrap_metrics['mape']):.2f}% ± {np.std(bootstrap_metrics['mape']):.2f}%\")\n",
    "print(f\"📌 MMRE    : {np.mean(bootstrap_metrics['mmre']):.4f} ± {np.std(bootstrap_metrics['mmre']):.4f}\")\n",
    "print(f\"📌 MdMRE   : {np.mean(bootstrap_metrics['mdmre']):.4f} ± {np.std(bootstrap_metrics['mdmre']):.4f}\")\n",
    "print(f\"📌 PRED(25): {np.mean(bootstrap_metrics['pred25']):.2f}% ± {np.std(bootstrap_metrics['pred25']):.2f}%\")\n",
    "\n",
    "# Lưu kết quả đánh giá\n",
    "results = {\n",
    "    'MSE': mse,\n",
    "    'RMSE': rmse,\n",
    "    'MAE': mae,\n",
    "    'R2 NRC': r2,\n",
    "    'MAPE': mape,\n",
    "    'MMRE': mmre,\n",
    "    'MdMRE': mdmre,\n",
    "    'PRED(25)': pred25,\n",
    "    'Bootstrap_MSE_Mean': np.mean(bootstrap_metrics['mse']),\n",
    "    'Bootstrap_MSE_Std': np.std(bootstrap_metrics['mse']),\n",
    "    'Bootstrap_MAE_Mean': np.mean(bootstrap_metrics['mae']),\n",
    "    'Bootstrap_MAE_Std': np.std(bootstrap_metrics['mae']),\n",
    "    'Bootstrap_R2_Mean': np.mean(bootstrap_metrics['r2']),\n",
    "    'Bootstrap_R2_Std': np.std(bootstrap_metrics['r2']),\n",
    "    'Bootstrap_MAPE_Mean': np.mean(bootstrap_metrics['mape']),\n",
    "    'Bootstrap_MAPE_Std': np.std(bootstrap_metrics['mape']),\n",
    "    'Bootstrap_MMRE_Mean': np.mean(bootstrap_metrics['mmre']),\n",
    "    'Bootstrap_MMRE_Std': np.std(bootstrap_metrics['mmre']),\n",
    "    'Bootstrap_MdMRE_Mean': np.mean(bootstrap_metrics['mdmre']),\n",
    "    'Bootstrap_MdMRE_Std': np.std(bootstrap_metrics['mdmre']),\n",
    "    'Bootstrap_PRED25_Mean': np.mean(bootstrap_metrics['pred25']),\n",
    "    'Bootstrap_PRED25_Std': np.std(bootstrap_metrics['pred25'])\n",
    "}\n",
    "\n",
    "results_df = pd.DataFrame([results])\n",
    "results_df.to_csv('lstm_evaluation_results.csv', index=False)\n",
    "print(\"\\nĐã lưu kết quả đánh giá vào 'lstm_evaluation_results.csv'\")\n",
    "\n",
    "# Trực quan hóa kết quả\n",
    "plt.figure(figsize=(15, 12))\n",
    "\n",
    "# Loss\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Predicted vs Actual\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.scatter(y_test_orig, y_pred_orig, alpha=0.5)\n",
    "plt.plot([y_test_orig.min(), y_test_orig.max()], [y_test_orig.min(), y_test_orig.max()], 'r--')\n",
    "plt.title('Predicted vs Actual Effort (Original Scale)')\n",
    "plt.xlabel('Actual Effort')\n",
    "plt.ylabel('Predicted Effort')\n",
    "\n",
    "# Error Distribution\n",
    "errors = y_test_orig - y_pred_orig\n",
    "plt.subplot(2, 2, 3)\n",
    "sns.histplot(errors, kde=True)\n",
    "plt.title('Error Distribution')\n",
    "plt.xlabel('Prediction Error')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Bootstrap PRED(25)\n",
    "plt.subplot(2, 2, 4)\n",
    "sns.boxplot(y=bootstrap_metrics['pred25'])\n",
    "plt.title('Bootstrap PRED(25) Distribution')\n",
    "plt.ylabel('PRED(25) (%)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('lstm_visualization_results.png')\n",
    "plt.close()\n",
    "print(\"\\nĐã lưu hình ảnh trực quan hóa vào 'lstm_visualization_results.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc88f616",
   "metadata": {},
   "source": [
    "# RFBN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e32517f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Kiểm tra dữ liệu ===\n",
      "Kích thước: (24, 7)\n",
      "Các cột: ['Input', 'Output', 'Inquiry', 'File', 'FPAdj', 'RawFPcounts', 'Effort']\n",
      "Mẫu 5 hàng đầu tiên:\n",
      "      Input    Output   Inquiry      File     FPAdj  RawFPcounts    Effort\n",
      "0 -0.544978  2.676655  2.425098  2.235928  0.078752     2.030029  1.905014\n",
      "1  2.060336  1.583672  2.425098  1.423982  0.078752     2.030029  1.905014\n",
      "2  1.835512 -0.602296 -1.141891 -0.347538 -1.433293    -0.158757 -0.364603\n",
      "3  0.248519  0.413717  0.417448 -0.347538  1.212786     0.236318  0.476385\n",
      "4 -1.338474  0.690812 -1.063924 -0.568978 -0.677270    -0.336098  1.123946\n",
      "\n",
      "Thông tin dữ liệu:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24 entries, 0 to 23\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Input        24 non-null     float64\n",
      " 1   Output       24 non-null     float64\n",
      " 2   Inquiry      24 non-null     float64\n",
      " 3   File         24 non-null     float64\n",
      " 4   FPAdj        24 non-null     float64\n",
      " 5   RawFPcounts  24 non-null     float64\n",
      " 6   Effort       24 non-null     float64\n",
      "dtypes: float64(7)\n",
      "memory usage: 1.4 KB\n",
      "None\n",
      "\n",
      "=== Sau khi tăng cường dữ liệu bằng nhiễu Gaussian ===\n",
      "X_augmented shape: (72, 6)\n",
      "y_augmented shape: (72,)\n",
      "\n",
      "=== Kích thước dữ liệu sau tăng cường ===\n",
      "X_augmented shape: (72, 6)\n",
      "y_augmented shape: (72,)\n",
      "\n",
      "✅ Kích thước dữ liệu RBFN:\n",
      " - X_train: (61, 6)\n",
      " - X_test : (11, 6)\n",
      "🚀 Chạy PSO để tìm siêu tham số tối ưu...\n",
      "\n",
      "🔁 Iteration 1/15\n",
      "✅ Cập nhật g_best: Score = 0.3652\n",
      "✅ Cập nhật g_best: Score = 0.3266\n",
      "✅ Cập nhật g_best: Score = 0.2922\n",
      "\n",
      "🔁 Iteration 2/15\n",
      "✅ Cập nhật g_best: Score = 0.2752\n",
      "\n",
      "🔁 Iteration 3/15\n",
      "✅ Cập nhật g_best: Score = 0.2641\n",
      "\n",
      "🔁 Iteration 4/15\n",
      "\n",
      "🔁 Iteration 5/15\n",
      "✅ Cập nhật g_best: Score = 0.2549\n",
      "✅ Cập nhật g_best: Score = 0.2474\n",
      "\n",
      "🔁 Iteration 6/15\n",
      "\n",
      "🔁 Iteration 7/15\n",
      "\n",
      "🔁 Iteration 8/15\n",
      "\n",
      "🔁 Iteration 9/15\n",
      "\n",
      "🔁 Iteration 10/15\n",
      "\n",
      "🔁 Iteration 11/15\n",
      "\n",
      "🔁 Iteration 12/15\n",
      "\n",
      "🔁 Iteration 13/15\n",
      "\n",
      "🔁 Iteration 14/15\n",
      "\n",
      "🔁 Iteration 15/15\n",
      "🏆 Siêu tham số tốt nhất: {'n_centers': 50, 'sigma': 0.1, 'l2_reg': 0.001, 'learning_rate': np.float64(0.008013404752108903), 'batch_size': 27, 'epochs': 151}\n",
      "📉 Score tốt nhất: 0.2474\n",
      "\n",
      "📂 Fold 1/5\n",
      "✅ Fold 1 RMSE: 0.8432\n",
      "\n",
      "📂 Fold 2/5\n",
      "✅ Fold 2 RMSE: 0.3420\n",
      "\n",
      "📂 Fold 3/5\n",
      "✅ Fold 3 RMSE: 0.1061\n",
      "\n",
      "📂 Fold 4/5\n",
      "✅ Fold 4 RMSE: 0.0544\n",
      "\n",
      "📂 Fold 5/5\n",
      "✅ Fold 5 RMSE: 0.0467\n",
      "\n",
      "📊 RMSE trung bình qua 5 folds: 0.2785\n",
      "\n",
      "📈 Kết quả đánh giá bootstrap (trên giá trị đã scale):\n",
      "📌 MSE     : 0.2136 ± 0.1224\n",
      "📌 RMSE    : 0.4397 ± 0.1424\n",
      "📌 MAE     : 0.2877 ± 0.1136\n",
      "📌 R²      : 0.7637 ± 0.1544\n",
      "📌 MAPE    : 29.84% ± 9.51%\n",
      "📌 MMRE    : 0.2984 ± 0.0951\n",
      "📌 MdMRE   : 0.2184 ± 0.0954\n",
      "📌 PRED(25): 55.24% ± 15.23%\n",
      "\n",
      "Đã lưu kết quả đánh giá vào 'rbfn_evaluation_results_scaled.csv'\n",
      "\n",
      "Đã lưu hình ảnh trực quan hóa vào 'rbfn_visualization_results_scaled.png'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, Layer\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.cluster import KMeans\n",
    "from uuid import uuid4\n",
    "\n",
    "# Thiết lập seed để tái lập\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Hàm tính các chỉ số đánh giá\n",
    "def calculate_mape(y_true, y_pred):\n",
    "    mask = y_true != 0\n",
    "    if np.sum(mask) == 0:\n",
    "        return np.nan\n",
    "    return np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100\n",
    "\n",
    "def calculate_mmre(y_true, y_pred):\n",
    "    mask = y_true != 0\n",
    "    if np.sum(mask) == 0:\n",
    "        return np.nan\n",
    "    return np.mean(np.abs(((y_true[mask] - y_pred[mask]) / y_true[mask])))\n",
    "\n",
    "def calculate_mdmre(y_true, y_pred):\n",
    "    mask = y_true != 0\n",
    "    if np.sum(mask) == 0:\n",
    "        return np.nan\n",
    "    return np.median(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask]))\n",
    "\n",
    "def calculate_pred25(y_true, y_pred):\n",
    "    mask = y_true != 0\n",
    "    if np.sum(mask) == 0:\n",
    "        return np.nan\n",
    "    mre = np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])\n",
    "    return np.mean(mre <= 0.25) * 100\n",
    "\n",
    "# Định nghĩa tầng RBF tùy chỉnh\n",
    "class RBFLayer(Layer):\n",
    "    def __init__(self, n_centers, centers=None, sigma=1.0, **kwargs):\n",
    "        super(RBFLayer, self).__init__(**kwargs)\n",
    "        self.n_centers = n_centers\n",
    "        self.centers = centers  # Trung tâm được truyền từ KMeans\n",
    "        self.sigma = sigma\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if self.centers is None:\n",
    "            # Nếu không có trung tâm, khởi tạo ngẫu nhiên\n",
    "            self.centers = self.add_weight(name='centers',\n",
    "                                           shape=(self.n_centers, input_shape[-1]),\n",
    "                                           initializer='uniform',\n",
    "                                           trainable=False)\n",
    "        else:\n",
    "            # Sử dụng trung tâm từ KMeans\n",
    "            self.centers = self.add_weight(name='centers',\n",
    "                                           shape=(self.n_centers, input_shape[-1]),\n",
    "                                           initializer=tf.keras.initializers.Constant(self.centers),\n",
    "                                           trainable=False)\n",
    "        self.sigma = self.add_weight(name='sigma',\n",
    "                                     shape=(),\n",
    "                                     initializer=tf.keras.initializers.Constant(self.sigma),\n",
    "                                     trainable=True)\n",
    "        super(RBFLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        diff = tf.expand_dims(inputs, axis=1) - self.centers  # (samples, n_centers, features)\n",
    "        l2 = tf.reduce_sum(tf.square(diff), axis=-1)  # (samples, n_centers)\n",
    "        return tf.exp(-l2 / (2.0 * tf.square(self.sigma)))\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.n_centers)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(RBFLayer, self).get_config()\n",
    "        config.update({\n",
    "            'n_centers': self.n_centers,\n",
    "            'centers': self.centers.numpy() if isinstance(self.centers, tf.Variable) else self.centers,\n",
    "            'sigma': self.sigma.numpy() if isinstance(self.sigma, tf.Variable) else self.sigma\n",
    "        })\n",
    "        return config\n",
    "\n",
    "# Đọc dữ liệu đã tiền xử lý\n",
    "df = pd.read_csv('albrecht_cleaned.csv')\n",
    "\n",
    "# Kiểm tra dữ liệu\n",
    "print(\"=== Kiểm tra dữ liệu ===\")\n",
    "print(\"Kích thước:\", df.shape)\n",
    "print(\"Các cột:\", df.columns.tolist())\n",
    "print(\"Mẫu 5 hàng đầu tiên:\")\n",
    "print(df.head())\n",
    "print(\"\\nThông tin dữ liệu:\")\n",
    "print(df.info())\n",
    "\n",
    "# Chọn đặc trưng và biến mục tiêu\n",
    "features = [col for col in df.columns if col not in ['Project', 'Effort', 'Effort_log']]\n",
    "X = df[features].values\n",
    "y = df['Effort'].values  # Sử dụng Effort đã được scale từ file test.csv\n",
    "\n",
    "# Tăng cường dữ liệu bằng nhiễu Gaussian\n",
    "def add_gaussian_noise(X, noise_factor=0.05):\n",
    "    noise = np.random.normal(loc=0, scale=noise_factor, size=X.shape)\n",
    "    return X + noise\n",
    "\n",
    "X_augmented = X.copy()\n",
    "y_augmented = y.copy()\n",
    "for _ in range(2):  # Tạo thêm 2 bản sao với nhiễu\n",
    "    X_noisy = add_gaussian_noise(X, noise_factor=0.05)\n",
    "    X_augmented = np.vstack((X_augmented, X_noisy))\n",
    "    y_augmented = np.hstack((y_augmented, y))\n",
    "\n",
    "print(\"\\n=== Sau khi tăng cường dữ liệu bằng nhiễu Gaussian ===\")\n",
    "print(\"X_augmented shape:\", X_augmented.shape)\n",
    "print(\"y_augmented shape:\", y_augmented.shape)\n",
    "\n",
    "# Không cần reshape cho RBFN vì dữ liệu là 2D\n",
    "print(\"\\n=== Kích thước dữ liệu sau tăng cường ===\")\n",
    "print(\"X_augmented shape:\", X_augmented.shape)\n",
    "print(\"y_augmented shape:\", y_augmented.shape)\n",
    "\n",
    "# Chia tập train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_augmented, y_augmented, test_size=0.15, random_state=42)\n",
    "\n",
    "print(f\"\\n✅ Kích thước dữ liệu RBFN:\")\n",
    "print(f\" - X_train: {X_train.shape}\")\n",
    "print(f\" - X_test : {X_test.shape}\")\n",
    "\n",
    "# Xây dựng mô hình RBFN\n",
    "def build_rbfn_model(n_centers=10, sigma=1.0, l2_reg=0.01, learning_rate=0.001):\n",
    "    # Đảm bảo l2_reg không âm và sigma dương\n",
    "    l2_reg = max(l2_reg, 0.001)\n",
    "    sigma = max(sigma, 0.1)\n",
    "    \n",
    "    # Sử dụng KMeans để khởi tạo centers\n",
    "    kmeans = KMeans(n_clusters=int(n_centers), random_state=42).fit(X_train)\n",
    "    centers = kmeans.cluster_centers_\n",
    "    \n",
    "    model = Sequential([\n",
    "        Input(shape=(X_train.shape[1],)),\n",
    "        RBFLayer(n_centers, centers=centers, sigma=sigma),\n",
    "        Dense(1, activation='linear', kernel_regularizer=l2(l2_reg))\n",
    "    ])\n",
    "    \n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss=tf.keras.losses.Huber(), metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# Không gian siêu tham số cho RBFN\n",
    "param_bounds = {\n",
    "    'n_centers': (5, 50),  # Số trung tâm (nơ-ron ẩn)\n",
    "    'sigma': (0.1, 5.0),  # Độ rộng của hàm Gaussian\n",
    "    'l2_reg': (0.001, 0.1),\n",
    "    'learning_rate': (1e-4, 1e-2),\n",
    "    'batch_size': (16, 64),\n",
    "    'epochs': (50, 150)\n",
    "}\n",
    "\n",
    "# Hàm mã hóa & giải mã particle\n",
    "def random_particle():\n",
    "    return np.array([\n",
    "        np.random.randint(param_bounds['n_centers'][0], param_bounds['n_centers'][1] + 1),\n",
    "        np.random.uniform(param_bounds['sigma'][0], param_bounds['sigma'][1]),\n",
    "        np.random.uniform(param_bounds['l2_reg'][0], param_bounds['l2_reg'][1]),\n",
    "        np.random.uniform(param_bounds['learning_rate'][0], param_bounds['learning_rate'][1]),\n",
    "        np.random.randint(param_bounds['batch_size'][0], param_bounds['batch_size'][1] + 1),\n",
    "        np.random.randint(param_bounds['epochs'][0], param_bounds['epochs'][1] + 1)\n",
    "    ])\n",
    "\n",
    "def decode_particle(particle):\n",
    "    params = {\n",
    "        'n_centers': int(particle[0]),\n",
    "        'sigma': particle[1],\n",
    "        'l2_reg': particle[2],\n",
    "        'learning_rate': particle[3],\n",
    "        'batch_size': int(particle[4]),\n",
    "        'epochs': int(particle[5])\n",
    "    }\n",
    "    # Đảm bảo l2_reg không âm và sigma dương\n",
    "    params['l2_reg'] = max(params['l2_reg'], 0.001)\n",
    "    params['l2_reg'] = min(params['l2_reg'], param_bounds['l2_reg'][1])\n",
    "    params['sigma'] = max(params['sigma'], 0.1)  # Sigma phải dương\n",
    "    return params\n",
    "\n",
    "# Hàm fitness cho PSO\n",
    "def fitness_function(particle):\n",
    "    params = decode_particle(particle)\n",
    "    model = build_rbfn_model(**{k: v for k, v in params.items() if k != 'batch_size' and k != 'epochs'})\n",
    "    \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    rmse_scores = []\n",
    "    \n",
    "    for train_idx, val_idx in kf.split(X_train):\n",
    "        X_tr, X_val = X_train[train_idx], X_train[val_idx]\n",
    "        y_tr, y_val = y_train[train_idx], y_train[val_idx]\n",
    "        \n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
    "        reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
    "        \n",
    "        model.fit(X_tr, y_tr, epochs=params['epochs'], batch_size=params['batch_size'], \n",
    "                  validation_split=0.2, verbose=0, callbacks=[early_stopping, reduce_lr])\n",
    "        y_pred = model.predict(X_val, verbose=0)\n",
    "        rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "        rmse_scores.append(rmse)\n",
    "    \n",
    "    return np.mean(rmse_scores)\n",
    "\n",
    "# Triển khai PSO\n",
    "def run_pso_rbfn(num_particles=10, max_iter=10):\n",
    "    dim = len(param_bounds)\n",
    "    bounds_array = np.array(list(param_bounds.values()))\n",
    "    \n",
    "    particles = [random_particle() for _ in range(num_particles)]\n",
    "    velocities = [np.zeros(dim) for _ in range(num_particles)]\n",
    "    \n",
    "    p_best_positions = particles.copy()\n",
    "    p_best_scores = [fitness_function(p) for p in particles]\n",
    "    \n",
    "    g_best_index = np.argmin(p_best_scores)\n",
    "    g_best_position = p_best_positions[g_best_index]\n",
    "    g_best_score = p_best_scores[g_best_index]\n",
    "    \n",
    "    w, c1, c2 = 0.5, 1.5, 1.5\n",
    "    \n",
    "    for iter in range(max_iter):\n",
    "        print(f\"\\n🔁 Iteration {iter + 1}/{max_iter}\")\n",
    "        for i in range(num_particles):\n",
    "            r1 = np.random.rand(dim)\n",
    "            r2 = np.random.rand(dim)\n",
    "            \n",
    "            velocities[i] = (\n",
    "                w * velocities[i]\n",
    "                + c1 * r1 * (p_best_positions[i] - particles[i])\n",
    "                + c2 * r2 * (g_best_position - particles[i])\n",
    "            )\n",
    "            \n",
    "            particles[i] += velocities[i]\n",
    "            particles[i] = np.clip(particles[i], bounds_array[:, 0], bounds_array[:, 1])\n",
    "            # Đảm bảo l2_reg không âm và sigma dương\n",
    "            particles[i][1] = max(particles[i][1], param_bounds['sigma'][0])  # sigma\n",
    "            particles[i][1] = min(particles[i][1], param_bounds['sigma'][1])\n",
    "            particles[i][2] = max(particles[i][2], param_bounds['l2_reg'][0])  # l2_reg\n",
    "            particles[i][2] = min(particles[i][2], param_bounds['l2_reg'][1])\n",
    "            \n",
    "            score = fitness_function(particles[i])\n",
    "            \n",
    "            if score < p_best_scores[i]:\n",
    "                p_best_scores[i] = score\n",
    "                p_best_positions[i] = particles[i]\n",
    "                \n",
    "            if score < g_best_score:\n",
    "                g_best_score = score\n",
    "                g_best_position = particles[i]\n",
    "                print(f\"✅ Cập nhật g_best: Score = {g_best_score:.4f}\")\n",
    "    \n",
    "    return g_best_position, g_best_score\n",
    "\n",
    "# Chạy PSO\n",
    "print(\"🚀 Chạy PSO để tìm siêu tham số tối ưu...\")\n",
    "best_particle, best_score = run_pso_rbfn(num_particles=10, max_iter=15)\n",
    "best_params = decode_particle(best_particle)\n",
    "print(f\"🏆 Siêu tham số tốt nhất: {best_params}\")\n",
    "print(f\"📉 Score tốt nhất: {best_score:.4f}\")\n",
    "\n",
    "# Huấn luyện mô hình tối ưu\n",
    "model_optimal = build_rbfn_model(**{k: v for k, v in best_params.items() if k != 'batch_size' and k != 'epochs'})\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "rmse_scores_optimal = []\n",
    "history = None\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_train)):\n",
    "    print(f\"\\n📂 Fold {fold + 1}/5\")\n",
    "    X_tr, X_val = X_train[train_idx], X_train[val_idx]\n",
    "    y_tr, y_val = y_train[train_idx], y_train[val_idx]\n",
    "    \n",
    "    history = model_optimal.fit(X_tr, y_tr, epochs=best_params['epochs'], batch_size=best_params['batch_size'], \n",
    "                               validation_split=0.2, verbose=0, callbacks=[early_stopping, reduce_lr])\n",
    "    y_pred = model_optimal.predict(X_val, verbose=0)\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "    rmse_scores_optimal.append(rmse)\n",
    "    print(f\"✅ Fold {fold + 1} RMSE: {rmse:.4f}\")\n",
    "\n",
    "print(f\"\\n📊 RMSE trung bình qua 5 folds: {np.mean(rmse_scores_optimal):.4f}\")\n",
    "\n",
    "# Đánh giá trên tập test\n",
    "y_pred = model_optimal.predict(X_test, verbose=0).flatten()\n",
    "\n",
    "# Tính các chỉ số đánh giá trên giá trị đã scale\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mape = calculate_mape(y_test, y_pred)\n",
    "mmre = calculate_mmre(y_test, y_pred)\n",
    "mdmre = calculate_mdmre(y_test, y_pred)\n",
    "pred25 = calculate_pred25(y_test, y_pred)\n",
    "\n",
    "# Đánh giá bootstrap\n",
    "n_bootstraps = 500\n",
    "bootstrap_metrics = {'mse': [], 'mae': [], 'r2': [], 'mape': [], 'mmre': [], 'mdmre': [], 'pred25': []}\n",
    "\n",
    "for _ in range(n_bootstraps):\n",
    "    indices = np.random.choice(len(y_test), len(y_test), replace=True)\n",
    "    y_test_boot = y_test[indices]\n",
    "    y_pred_boot = y_pred[indices]\n",
    "    bootstrap_metrics['mse'].append(mean_squared_error(y_test_boot, y_pred_boot))\n",
    "    bootstrap_metrics['mae'].append(mean_absolute_error(y_test_boot, y_pred_boot))\n",
    "    bootstrap_metrics['r2'].append(r2_score(y_test_boot, y_pred_boot))\n",
    "    bootstrap_metrics['mape'].append(calculate_mape(y_test_boot, y_pred_boot))\n",
    "    bootstrap_metrics['mmre'].append(calculate_mmre(y_test_boot, y_pred_boot))\n",
    "    bootstrap_metrics['mdmre'].append(calculate_mdmre(y_test_boot, y_pred_boot))\n",
    "    bootstrap_metrics['pred25'].append(calculate_pred25(y_test_boot, y_pred_boot))\n",
    "\n",
    "# In kết quả\n",
    "print(\"\\n📈 Kết quả đánh giá bootstrap (trên giá trị đã scale):\")\n",
    "print(f\"📌 MSE     : {np.mean(bootstrap_metrics['mse']):.4f} ± {np.std(bootstrap_metrics['mse']):.4f}\")\n",
    "print(f\"📌 RMSE    : {np.mean(np.sqrt(bootstrap_metrics['mse'])):.4f} ± {np.std(np.sqrt(bootstrap_metrics['mse'])):.4f}\")\n",
    "print(f\"📌 MAE     : {np.mean(bootstrap_metrics['mae']):.4f} ± {np.std(bootstrap_metrics['mae']):.4f}\")\n",
    "print(f\"📌 R²      : {np.mean(bootstrap_metrics['r2']):.4f} ± {np.std(bootstrap_metrics['r2']):.4f}\")\n",
    "print(f\"📌 MAPE    : {np.mean(bootstrap_metrics['mape']):.2f}% ± {np.std(bootstrap_metrics['mape']):.2f}%\")\n",
    "print(f\"📌 MMRE    : {np.mean(bootstrap_metrics['mmre']):.4f} ± {np.std(bootstrap_metrics['mmre']):.4f}\")\n",
    "print(f\"📌 MdMRE   : {np.mean(bootstrap_metrics['mdmre']):.4f} ± {np.std(bootstrap_metrics['mdmre']):.4f}\")\n",
    "print(f\"📌 PRED(25): {np.mean(bootstrap_metrics['pred25']):.2f}% ± {np.std(bootstrap_metrics['pred25']):.2f}%\")\n",
    "\n",
    "# Lưu kết quả đánh giá\n",
    "results = {\n",
    "    'MSE': mse,\n",
    "    'RMSE': rmse,\n",
    "    'MAE': mae,\n",
    "    'R2': r2,\n",
    "    'MAPE': mape,\n",
    "    'MMRE': mmre,\n",
    "    'MdMRE': mdmre,\n",
    "    'PRED(25)': pred25,\n",
    "    'Bootstrap_MSE_Mean': np.mean(bootstrap_metrics['mse']),\n",
    "    'Bootstrap_MSE_Std': np.std(bootstrap_metrics['mse']),\n",
    "    'Bootstrap_MAE_Mean': np.mean(bootstrap_metrics['mae']),\n",
    "    'Bootstrap_MAE_Std': np.std(bootstrap_metrics['mae']),\n",
    "    'Bootstrap_R2_Mean': np.mean(bootstrap_metrics['r2']),\n",
    "    'Bootstrap_R2_Std': np.std(bootstrap_metrics['r2']),\n",
    "    'Bootstrap_MAPE_Mean': np.mean(bootstrap_metrics['mape']),\n",
    "    'Bootstrap_MAPE_Std': np.std(bootstrap_metrics['mape']),\n",
    "    'Bootstrap_MMRE_Mean': np.mean(bootstrap_metrics['mmre']),\n",
    "    'Bootstrap_MMRE_Std': np.std(bootstrap_metrics['mmre']),\n",
    "    'Bootstrap_MdMRE_Mean': np.mean(bootstrap_metrics['mdmre']),\n",
    "    'Bootstrap_MdMRE_Std': np.std(bootstrap_metrics['mdmre']),\n",
    "    'Bootstrap_PRED25_Mean': np.mean(bootstrap_metrics['pred25']),\n",
    "    'Bootstrap_PRED25_Std': np.std(bootstrap_metrics['pred25'])\n",
    "}\n",
    "\n",
    "results_df = pd.DataFrame([results])\n",
    "results_df.to_csv('rbfn_evaluation_results_scaled.csv', index=False)\n",
    "print(\"\\nĐã lưu kết quả đánh giá vào 'rbfn_evaluation_results_scaled.csv'\")\n",
    "\n",
    "# Trực quan hóa kết quả\n",
    "plt.figure(figsize=(15, 12))\n",
    "\n",
    "# Loss\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Huber Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Predicted vs Actual\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "plt.title('Predicted vs Actual Effort (Scaled)')\n",
    "plt.xlabel('Actual Effort (Scaled)')\n",
    "plt.ylabel('Predicted Effort (Scaled)')\n",
    "\n",
    "# Error Distribution\n",
    "errors = y_test - y_pred\n",
    "plt.subplot(2, 2, 3)\n",
    "sns.histplot(errors, kde=True)\n",
    "plt.title('Error Distribution')\n",
    "plt.xlabel('Prediction Error (Scaled)')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Bootstrap RMSE\n",
    "plt.subplot(2, 2, 4)\n",
    "sns.boxplot(y=np.sqrt(bootstrap_metrics['mse']))\n",
    "plt.title('Bootstrap RMSE Distribution (Scaled)')\n",
    "plt.ylabel('RMSE (Scaled)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('rbfn_visualization_results_scaled.png')\n",
    "plt.close()\n",
    "print(\"\\nĐã lưu hình ảnh trực quan hóa vào 'rbfn_visualization_results_scaled.png'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11fecd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Kiá»ƒu dá»¯ liá»‡u sau khi chuyá»ƒn Ä‘á»•i:\n",
      "AFP                 int64\n",
      "Input               int64\n",
      "Output              int64\n",
      "Enquiry             int64\n",
      "File                int64\n",
      "Interface           int64\n",
      "Added               int64\n",
      "Changed             int64\n",
      "Deleted             int64\n",
      "Resource            int64\n",
      "Duration          float64\n",
      "AdjFactor         float64\n",
      "Effort              int64\n",
      "DevType_Maint     float64\n",
      "DevType_NewDev    float64\n",
      "dtype: object\n",
      "\n",
      "=== Sau khi tÄƒng cÆ°á»ng dá»¯ liá»‡u báº±ng nhiá»…u Gaussian ===\n",
      "X_augmented shape: (1497, 14)\n",
      "y_augmented shape: (1497,)\n",
      "\n",
      "=== KÃ­ch thÆ°á»›c dá»¯ liá»‡u sau reshape ===\n",
      "X_augmented shape: (1497, 14, 1)\n",
      "y_augmented shape: (1497,)\n",
      "\n",
      "âœ… KÃ­ch thÆ°á»›c dá»¯ liá»‡u CNN:\n",
      " - X_train: (1272, 14, 1)\n",
      " - X_test : (225, 14, 1)\n",
      "ğŸš€ Cháº¡y PSO Ä‘á»ƒ tÃ¬m siÃªu tham sá»‘ tá»‘i Æ°u...\n",
      "\n",
      "ğŸ” Iteration 1/10\n",
      "\n",
      "ğŸ” Iteration 2/10\n",
      "âœ… Cáº­p nháº­t g_best: Score = 4102.3683\n",
      "âœ… Cáº­p nháº­t g_best: Score = 3857.3104\n",
      "\n",
      "ğŸ” Iteration 3/10\n",
      "\n",
      "ğŸ” Iteration 4/10\n",
      "\n",
      "ğŸ” Iteration 5/10\n",
      "\n",
      "ğŸ” Iteration 6/10\n",
      "\n",
      "ğŸ” Iteration 7/10\n",
      "\n",
      "ğŸ” Iteration 8/10\n",
      "\n",
      "ğŸ” Iteration 9/10\n",
      "\n",
      "ğŸ” Iteration 10/10\n",
      "ğŸ† SiÃªu tham sá»‘ tá»‘t nháº¥t: {'filters': 18, 'l2_reg': np.float64(0.029648577574436424), 'dense_units': 34, 'dropout_rate': np.float64(0.3855552347780243), 'learning_rate': np.float64(0.005294688491675608), 'batch_size': 23, 'epochs': 52}\n",
      "ğŸ“‰ Score tá»‘t nháº¥t: 3857.3104\n",
      "\n",
      "ğŸ“‚ Fold 1/3\n",
      "âœ… Fold 1 RMSE: 5210.5975\n",
      "\n",
      "ğŸ“‚ Fold 2/3\n",
      "âœ… Fold 2 RMSE: 4387.5066\n",
      "\n",
      "ğŸ“‚ Fold 3/3\n",
      "âœ… Fold 3 RMSE: 3324.1280\n",
      "\n",
      "ğŸ“Š RMSE trung bÃ¬nh qua 3 folds: 4307.4107\n",
      "\n",
      "ğŸ“ˆ Káº¿t quáº£ Ä‘Ã¡nh giÃ¡ bootstrap (trÃªn giÃ¡ trá»‹ Ä‘Ã£ chuáº©n hÃ³a):\n",
      "ğŸ“Œ MSE     : 19111506.8740 Â± 5707578.8154\n",
      "ğŸ“Œ RMSE    : 4323.4658 Â± 647.4181\n",
      "ğŸ“Œ MAE     : 2128.9801 Â± 247.1014\n",
      "ğŸ“Œ RÂ²      : 0.4966 Â± 0.0913\n",
      "ğŸ“Œ MAPE    : 107.93% Â± 16.31%\n",
      "ğŸ“Œ MMRE    : 1.0793 Â± 0.1631\n",
      "ğŸ“Œ MdMRE   : 0.5427 Â± 0.0413\n",
      "ğŸ“Œ PRED(25): 27.11% Â± 3.02%\n",
      "\n",
      "ÄÃ£ lÆ°u káº¿t quáº£ Ä‘Ã¡nh giÃ¡ vÃ o 'cnn_evaluation_results_china.csv'\n",
      "\n",
      "ÄÃ£ lÆ°u hÃ¬nh áº£nh trá»±c quan hÃ³a vÃ o 'cnn_visualization_results_china.png'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1. Äá»c dá»¯ liá»‡u\n",
    "df = pd.read_csv('albrecht_preprocessed.csv')\n",
    "\n",
    "# 2. KhÃ¡m phÃ¡ dá»¯ liá»‡u\n",
    "print(\"ThÃ´ng tin dá»¯ liá»‡u:\")\n",
    "print(df.info())\n",
    "print(\"\\n5 dÃ²ng Ä‘áº§u tiÃªn:\")\n",
    "print(df.head())\n",
    "print(\"\\nThá»‘ng kÃª mÃ´ táº£:\")\n",
    "print(df.describe())\n",
    "print(\"\\nPhÃ¢n bá»‘ biáº¿n Language:\")\n",
    "print(df['Language'].value_counts())\n",
    "\n",
    "# 3. Kiá»ƒm tra missing & trÃ¹ng láº·p\n",
    "print(\"\\nGiÃ¡ trá»‹ thiáº¿u:\")\n",
    "print(df.isnull().sum())\n",
    "print(\"Sá»‘ dÃ²ng trÃ¹ng láº·p:\", df.duplicated().sum())\n",
    "\n",
    "# 4. Kiá»ƒu dá»¯ liá»‡u\n",
    "df['Language'] = df['Language'].str.decode('utf-8')\n",
    "df['Project'] = df['Project'].astype(int)\n",
    "print(\"\\nKiá»ƒu dá»¯ liá»‡u sau khi xá»­ lÃ½:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# 5. MÃ£ hÃ³a biáº¿n phÃ¢n loáº¡i\n",
    "df = pd.get_dummies(df, columns=['Language'], prefix='Language')\n",
    "print(\"\\nDá»¯ liá»‡u sau mÃ£ hÃ³a:\")\n",
    "print(df.head())\n",
    "\n",
    "# 6. Xá»­ lÃ½ ngoáº¡i lá»‡\n",
    "df['TeamExp'] = df['TeamExp'].replace(-1, 0)\n",
    "df['ManagerExp'] = df['ManagerExp'].replace(-1, 0)\n",
    "print(\"\\nSá»‘ giÃ¡ trá»‹ Ã¢m trong TeamExp sau xá»­ lÃ½:\", (df['TeamExp'] < 0).sum())\n",
    "print(\"Sá»‘ giÃ¡ trá»‹ Ã¢m trong ManagerExp sau xá»­ lÃ½:\", (df['ManagerExp'] < 0).sum())\n",
    "\n",
    "# 7. Táº¡o Ä‘áº·c trÆ°ng má»›i (trÆ°á»›c chuáº©n hÃ³a)\n",
    "df['Effort_per_Length'] = df['Effort'] / df['Length']\n",
    "df['Total_Function_Size'] = df['Transactions'] + df['Entities']\n",
    "df['Effort_log'] = np.log1p(df['Effort'])\n",
    "\n",
    "print(\"\\nCÃ¡c Ä‘áº·c trÆ°ng má»›i:\")\n",
    "print(df[['Effort_per_Length', 'Total_Function_Size', 'Effort_log']].head())\n",
    "\n",
    "# 8. Chuáº©n hÃ³a dá»¯ liá»‡u\n",
    "numeric_cols = ['TeamExp', 'ManagerExp', 'YearEnd', 'Length', 'Effort', \n",
    "                'Transactions', 'Entities', 'PointsNonAdjust', 'Adjustment', 'PointsAjust',\n",
    "                'Effort_per_Length', 'Total_Function_Size']\n",
    "scaler = StandardScaler()\n",
    "df[numeric_cols] = scaler.fit_transform(df[numeric_cols])\n",
    "\n",
    "print(\"\\nDá»¯ liá»‡u sau chuáº©n hÃ³a:\")\n",
    "print(df[numeric_cols].describe())\n",
    "\n",
    "# 9. PhÃ¢n tÃ­ch tÆ°Æ¡ng quan\n",
    "correlation_matrix = df[numeric_cols + ['Effort_log']].corr()\n",
    "print(\"\\nTÆ°Æ¡ng quan vá»›i Effort_log:\")\n",
    "print(correlation_matrix['Effort_log'].sort_values(ascending=False))\n",
    "\n",
    "# 10. TÃ¡ch X vÃ  y\n",
    "X = df.drop(columns=['Effort', 'Effort_log']) \n",
    "y = df['Effort_log']\n",
    "\n",
    "# 11. Chia táº­p train/test/val\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.33, random_state=42)\n",
    "\n",
    "print(\"\\nKÃ­ch thÆ°á»›c táº­p train:\", X_train.shape)\n",
    "print(\"KÃ­ch thÆ°á»›c táº­p test:\", X_test.shape)\n",
    "print(\"KÃ­ch thÆ°á»›c táº­p validation:\", X_val.shape)\n",
    "\n",
    "# 12. LÆ°u dá»¯ liá»‡u Ä‘Ã£ xá»­ lÃ½\n",
    "df.to_csv('test.csv', index=False)\n",
    "print(\"\\nÄÃ£ lÆ°u káº¿t quáº£ vÃ o file 'desharnais_preprocessed.csv'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
